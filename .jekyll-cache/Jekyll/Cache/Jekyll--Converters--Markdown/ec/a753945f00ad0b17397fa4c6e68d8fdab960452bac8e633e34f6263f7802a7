I"Õ<hr />

<div style="font-weight:500; font-size:1.0em; margin-left: 1em; margin-right: 1em;text-align:justify; ">
<b style="color:#d7385e;font-size:1.2">ì •ê·œí™”</b>ëŠ” ë”¥ëŸ¬ë‹ì˜ ì¶œí˜„ ì´ì „ì—ë„ ìˆ˜ì‹­ë…„ ë™ì•ˆ ì‚¬ìš©ë˜ì–´ ì™”ë‹¤. ì„ í˜• íšŒê·€ëª¨í˜•ì´ë‚˜ ë¡œì§€ìŠ¤í‹± íšŒê·€ëª¨í˜• ê°™ì€ ì„ í˜• ëª¨ë¸ì€ ê°„ë‹¨í•˜ê³  íš¨ê³¼ì ì¸ ì •ê·œí™”ê°€ ê°€ëŠ¥í•˜ë‹¤. ë§ì€ ì •ê·œí™” ë°©ë²•ì€ ëª©ì í•¨ìˆ˜ $J$ì— íŒŒë¼ë¯¸í„° norm penalty $\Omega(\theta)$ë¥¼ ì¶”ê°€í•˜ì—¬ ëª¨ë¸ì˜ capacityë¥¼ ì œí•œí•˜ëŠ” ê²ƒì— ê¸°ì´ˆí•œë‹¤. ì •ê·œí™”ëœ ëª©ì í•¨ìˆ˜ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤. 
<p align="center">
$$
\tilde{J}(\boldsymbol{\theta} ; \boldsymbol{X}, \boldsymbol{y})=J(\boldsymbol{\theta} ; \boldsymbol{X}, \boldsymbol{y})+\alpha \Omega(\boldsymbol{\theta}), \quad \text { where } \alpha \in[0, \infty)
$$
</p>
$\alpha$ë¥¼ 0ìœ¼ë¡œ ì„¤ì •í•˜ë©´ ì •ê·œí™”ê°€ ë˜ì§€ ì•Šê³  $\alpha$ì˜ ê°’ì´ í´ìˆ˜ë¡ ë” ì •ê·œí™”ëœë‹¤. <b style="color:#d7385e;font-size:1.2">parameter norm</b> $\Omega$ì— ëŒ€í•´ ë‹¤ë¥¸ ì†”ë£¨ì…˜ì´ ë” ì„ í˜¸ë  ìˆ˜ ìˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œ ê° ê³„ì¸µì—ì„œ affine ë³€í™˜ì˜ ê°€ì¤‘ì¹˜ì— ëŒ€í•´ì„œë§Œ íŒ¨ë„í‹°ë¥¼ ì£¼ê³  í¸ì°¨(bias)ë¥¼ ì •ê·œí™”í•˜ì§€ ì•ŠëŠ” íŒŒë¼ë¯¸í„° norm penalty $\Omega$ë¥¼ ì‚¬ìš©í•œë‹¤. í¸ì°¨ë¥¼ ì •í™•í•˜ê²Œ fití•˜ê¸° ìœ„í•´ ê°€ì¤‘ì¹˜ë³´ë‹¤ ë” ì ì€ ë°ì´í„°ê°€ í•„ìš”í•˜ê³  í¸ì°¨ íŒŒë¼ë¯¸í„° ì •ê·œí™”ëŠ” ìƒë‹¹í•œ underfitting ì–‘ì„ ë„ì…í•  ìˆ˜ ìˆë‹¤. 
<br /><br />
<span style="font-weight:700; font-size:1.3em;  margin-right: 1em;">
$L^2$ Parameter Regularization
</span>
<br /><br />
$L^2$ parameter norm penaltyëŠ” í”íˆ <b style="color:#d7385e;font-size:1.2">weight decay</b>ë¡œ ì•Œë ¤ì ¸ ìˆë‹¤. 
$$
\begin{array}{c}\Omega(\boldsymbol{\theta})=\frac{1}{2}\|\boldsymbol{w}\|_{2}^{2} \\ \tilde{J}(\boldsymbol{w} ; \boldsymbol{X}, \boldsymbol{y})=\frac{\alpha}{2} \boldsymbol{w}^{\top} \boldsymbol{w}+J(\boldsymbol{w} ; \boldsymbol{X}, \boldsymbol{y}) \\ \nabla_{\boldsymbol{w}} \tilde{J}(\boldsymbol{w} ; \boldsymbol{X}, \boldsymbol{y})=\alpha \boldsymbol{w}+\nabla_{\boldsymbol{w}} J(\boldsymbol{w} ; \boldsymbol{X}, \boldsymbol{y})\end{array}
$$
single gradient stepì„ ìˆ˜í–‰í•˜ì—¬ ê°€ì¤‘ì¹˜ë¥¼ ì—…ë°ì´íŠ¸ í•˜ëŠ” ë°©ë²•ì€ ë‹¤ìŒê³¼ ê°™ë‹¤. 
$$

\begin{array}{l}\boldsymbol{w} \leftarrow \boldsymbol{w}-\epsilon\left(\alpha \boldsymbol{w}+\nabla_{\boldsymbol{w}} J(\boldsymbol{w} ; \boldsymbol{X}, \boldsymbol{y})\right) \\ \boldsymbol{w} \leftarrow(1-\epsilon \alpha) \boldsymbol{w}-\epsilon \nabla_{\boldsymbol{w}} J(\boldsymbol{w} ; \boldsymbol{X}, \boldsymbol{y})\end{array}
$$

ì •ê·œí™”ë˜ì§€ ì•Šì€ íŠ¸ë ˆì´ë‹ ë¹„ìš©ì„ ìµœì†Œí™”í•˜ëŠ” ê°€ì¤‘ì¹˜ ê°’ê³¼ ì¸ì ‘í•œ ëª©ì  í•¨ìˆ˜ì— ëŒ€í•œ 2ì°¨(quadratic) ê·¼ì‚¬ë¥¼ ë§Œë“¤ì–´ ë¶„ì„ì„ ë‹¨ìˆœí•˜ê²Œ í•  ìˆ˜ ìˆë‹¤. ì—¬ê¸°ì„œ $H$ëŠ” $w^*$ì—ì„œ í‰ê°€ëœ $w$ì— ê´€í•œ $J$ì˜ í—¤ì‹œì•ˆ(Hessian) í–‰ë ¬ì´ë‹¤. 
$$
\begin{aligned} 
&amp;\boldsymbol{w}^{*}=\arg \min _{\boldsymbol{w}} J(\boldsymbol{w}) \\
&amp;\hat{J}(\boldsymbol{\theta}) =J\left(\boldsymbol{w}^{*}\right)+\frac{1}{2}\left(\boldsymbol{w}-\boldsymbol{w}^{*}\right)^{\top} \boldsymbol{H}\left(\boldsymbol{w}-\boldsymbol{w}^{*}\right) 
\end{aligned}
$$
gradientê°€ 0ì¼ ë•Œ $\hat{J}$ê°€ ìµœì†Œê°€ ëœë‹¤. 
$$
\nabla_{\boldsymbol{w}} \hat{J}(\boldsymbol{w})=\boldsymbol{H}\left(\boldsymbol{w}-\boldsymbol{w}^{*}\right)
$$
ì´ì œ ì •ê·œí™”ëœ $\hat{J}$ì˜ ìµœì†Œê°’ì„ ë‹¤ìŒê³¼ ê°™ì´ êµ¬í•  ìˆ˜ ìˆê²Œ ëœë‹¤. 
$$
\begin{array}{c}\alpha \tilde{\boldsymbol{w}}+\boldsymbol{H}\left(\tilde{\boldsymbol{w}}-\boldsymbol{w}^{*}\right)=0 \\ (\boldsymbol{H}+\alpha \boldsymbol{I}) \tilde{\boldsymbol{w}}=\boldsymbol{H} \boldsymbol{w}^{*} \\ \tilde{\boldsymbol{w}}=(\boldsymbol{H}+\alpha \boldsymbol{I})^{-1} \boldsymbol{H} \boldsymbol{w}^{*}\end{array}
$$
$\boldsymbol{H}=Q \Lambda Q^{\top}$ë¡œ ë¶„í•´(decompose) í•  ìˆ˜ ìˆë‹¤. 
$$
\begin{aligned} \tilde{w} &amp;=\left(Q \Lambda Q^{\top}+\alpha I\right)^{-1} Q \Lambda Q^{\top} w^{*} \\ &amp;=\left[Q(\Lambda+\alpha I) Q^{\top}\right]^{-1} Q \Lambda Q^{\top} w^{*} \\ &amp;=Q(\Lambda+\alpha I)^{-1} \Lambda Q^{\top} w^{*} \end{aligned}
$$
weight decayì˜ íš¨ê³¼ëŠ” $\boldsymbol{H}$ì˜ ê³ ìœ ë²¡í„°(eigenvector)ë¡œ ì •ì˜ëœ ì¶•ì„ ë”°ë¼ì„œ $w^{*}$ë¥¼ rescaleí•˜ëŠ” ê²ƒì´ë‹¤. $\boldsymbol{H}$ì˜ ië²ˆì§¸ ê³ ìœ ë²¡í„°ë¡œ ì •ë ¬ëœ $w^*$ì˜ ì„±ë¶„ì€ $\lambda_i / (\lambda_i+\alpha)$ ì˜ ì¸ìˆ˜ë¡œ ì¬ì¡°ì •ëœë‹¤. $\boldsymbol{H}$ì˜ ê³ ìœ ê°’(eigenvalue)ì´ ìƒëŒ€ì ìœ¼ë¡œ í° ë°©í–¥ì„ ë”°ë¥´ë©´ (ex. $\lambda_i &gt;&gt; \alpha$) ì •ê·œí™”ì˜ íš¨ê³¼ëŠ” ìƒëŒ€ì ìœ¼ë¡œ ì‘ì•„ì§„ë‹¤. ê·¸ëŸ¬ë‚˜ $\lambda_i &lt;&lt; \alpha$ì¸ ì„±ë¶„ì˜ í¬ê¸°ëŠ” ê±°ì˜ 0ì— ê°€ê¹Œìš¸ ì •ë„ë¡œ ì¤„ì–´ë“¤ ê²ƒì´ë‹¤. 
<br /><br />

<p align="center">
<img src="/images/post_img/AN7.png" width="400" height="300" />
</p>

<span style="font-weight:700; font-size:1.3em;  margin-right: 1em;">
$L^1$ Regularization
</span>
<br /><br />
$L^2$ weight decayê°€ weight decayì˜ ê°€ì¥ í”í•œ í˜•ì‹ì¸ ë°˜ë©´ì—, ëª¨ë¸ íŒŒë¼ë¯¸í„°ì˜ ì‚¬ì´ì¦ˆë¥¼ íŒ¨ë„ë¼ì´ì¦ˆ(penalize)í•˜ëŠ” ë‹¤ë¥¸ ë°©ë²•ë„ ìˆë‹¤. ê·¸ê²ƒì€ ë°”ë¡œ ë‹¤ìŒê³¼ ê°™ì´ $L^1$ ì •ê·œí™”ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ë‹¤. 
$$
\begin{array}{c}\Omega(\boldsymbol{\theta})=\|\boldsymbol{w}\|_{1}=\sum\left|w_{i}\right| \\ \tilde{J}(\boldsymbol{w} ; \boldsymbol{X}, \boldsymbol{y})=\alpha\|\boldsymbol{w}\|_{1}+J(\boldsymbol{w} ; \boldsymbol{X}, \boldsymbol{y}) \\ \nabla_{w} \tilde{J}(\boldsymbol{w} ; \boldsymbol{X}, \boldsymbol{y})=\alpha \operatorname{sign}(\boldsymbol{w})+\nabla_{w} J(\boldsymbol{X}, y ; \boldsymbol{w})\end{array}
$$
$H=\operatorname{diag}\left(\left[H_{1,1}, \ldots, H_{n, n}\right]\right)$ì™€ ê°™ì´ í—¤ì‹œì•ˆì´ ëŒ€ê°(diagonal)ì´ë¼ëŠ” <b style="color:#d7385e;font-size:1.2">ë”ìš± ê°„ë‹¨í•œ ê°€ì •</b>ì„ í•œë‹¤. ì´ ê°€ì •ì€ ì…ë ¥ íŠ¹ì§•ë“¤ ì‚¬ì´ì˜ ëª¨ë“  ìƒê´€ê´€ê³„(correlation)ë¥¼ ì œê±°í•˜ê¸° ìœ„í•´ ì„ í˜•íšŒê·€ ë¬¸ì œì— ëŒ€í•œ ë°ì´í„°ê°€ ì „ì²˜ë¦¬ëœ ê²½ìš°ì— ì ìš©ëœë‹¤.
<br /><br />
$L^1$ ì •ê·œí™”ëœ ëª©ì  í•¨ìˆ˜ì˜ 2ì°¨ ê·¼ì‚¬ëŠ” ë‹¤ìŒê³¼ ê°™ì´ íŒŒë¼ë¯¸í„°ì— ê±¸ì³ í•©(sum)ìœ¼ë¡œ ë¶„í•´ëœë‹¤. 
$$
\hat{J}(\boldsymbol{w} ; \boldsymbol{X}, \boldsymbol{y})=J\left(\boldsymbol{w}^{*} ; \boldsymbol{X}, \boldsymbol{y}\right)+\sum_{i}\left[\frac{1}{2} H_{i, i}\left(\boldsymbol{w}_{i}-\boldsymbol{w}_{i}^{*}\right)^{2}+\alpha\left|w_{i}\right|\right]
$$
ë¹„ìš©í•¨ìˆ˜ì˜ ê·¼ì‚¬ë¥¼ ìµœì†Œí™”í•˜ëŠ” ë¬¸ì œëŠ” ë‹¤ìŒê³¼ ê°™ì€ í˜•íƒœë¡œ ê° ì°¨ì› $i$ì— ëŒ€í•œ ë¶„ì„ì ì¸ ì†”ë£¨ì…˜ì„ ê°€ì§„ë‹¤. 
$$
w_{i}=\operatorname{sign}\left(w_{i}^{*}\right) \max \left\{\left|w_{i}^{*}\right|-\frac{\alpha}{H_{i, i}}, 0\right\}
$$

ëª¨ë“  $i$ì— ëŒ€í•´ $w^*_i &gt; 0$ì¸ ìƒí™©ì„ ê³ ë ¤í•´ë³´ì.

<ol>
<li>$w^*_i \le \alpha / H_{i,i}$ì¸ ê²½ìš° <br />
ì—¬ê¸°ì„œ $w_i = 0$ ì´ë‹¤. ì •ê·œí™”ëœ ëª©ì í•¨ìˆ˜ì— ëŒ€í•œ $J(w;X,y)$ì˜ contributionì´ $L^1$ ì •ê·œí™”ì— ì˜í•´ $i$ ë°©í–¥ìœ¼ë¡œ overwhelmed ë˜ê¸° ë•Œë¬¸ì— ë°œìƒí•œë‹¤.  </li>
<li>$w^*_i &gt; \alpha / H_{i,i}$ì¸ ê²½ìš° <br />
ì´ ê²½ìš°ëŠ” ì •ê·œí™”ê°€ $w_i$ì˜ ìµœì ê°’ì„ 0ìœ¼ë¡œ ì´ë™ì‹œí‚¤ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ $\alpha H_{i,i}$ì™€ ê°™ì€ ê±°ë¦¬ë§Œí¼ ê·¸ ë°©í–¥ìœ¼ë¡œë§Œ ì´ë™ì‹œí‚¨ë‹¤.</li>
</ol>

$L^2$ ì •ê·œí™”ì™€ ë¹„êµí•˜ì—¬ $L^1$ ì •ê·œí™”ëŠ” ë” <b style="color:#d7385e;font-size:1.2">í¬ì†Œí•œ(sparse)</b>í•œ ì†”ë£¨ì…˜ì„ ì¤€ë‹¤. $L^1$ ì •ê·œí™”ì— ì˜í•´ ìœ ë„ëœ í¬ì†Œì„±ì§ˆ (sparsity property)ì€ íŠ¹ì§• ì„ íƒ (feature selection) ë§¤ì»¤ë‹ˆì¦˜ìœ¼ë¡œ ê´‘ë²”ìœ„í•˜ê²Œ ì‚¬ìš©ë˜ì–´ì™”ë‹¤. 
</div>
:ET