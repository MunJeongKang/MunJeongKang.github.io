<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>코딩새내기 일상일지</title>
    <description>github blog</description>
    <link>http://munjeongkang.github.io/</link>
    <atom:link href="http://munjeongkang.github.io/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Thu, 16 Apr 2020 12:25:21 +0900</pubDate>
    <lastBuildDate>Thu, 16 Apr 2020 12:25:21 +0900</lastBuildDate>
    <generator>Jekyll v2.5.3</generator>
    
      <item>
        <title>IP - Lagrangian Duality</title>
        <description>&lt;hr /&gt;
&lt;div style=&quot;font-weight:500; font-size:1.0em; margin-left: 1em; margin-right: 1em;text-align:justify; &quot;&gt;

&lt;span style=&quot;font-weight:700; font-size:1.3em;  margin-right: 1em;&quot;&gt;
Lagrangian Relaxation
&lt;/span&gt;
&lt;br /&gt;&lt;br /&gt;
다음과 같은 IP(Integer program)를 생각해보자. 

$$
\begin{aligned}
    \text{(IP)} \quad &amp;amp;z=\max cx \\
    &amp;amp;Ax \le b \\
    &amp;amp;Dx \le d  \\
    &amp;amp;x \in Z^n_+
\end{aligned}
$$

어떤 제약조건만 있는 IP는 쉽게 풀린다는 관점에서 $Ax \le b$ 식을 &quot;nice&quot;하다고 가정해보자. 그러면 복잡한(complicating) 제약식 $Dx \le d$만 없다면 원래 IP 문제를 푸는 것 보다 relaxation이 더 쉬워진다. 많은 문제들이 이처럼 나이스한 제약과 복잡한 제약을 동시에 갖고 있는데, &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;복잡한 제약을 없앨 수 있다면 쉽게 문제를 풀 수도 있을 것&lt;/b&gt;이다. 예를 들어 TSP (traveling salesman problem)의 connectivity 제약식, UFL(uncapacitated facility location)의 client demand 제약식 등 복잡한 제약을 없앨 수 있다면 말이다. 그러나 그냥 없애버리면 중요한 제약식이 전부 무시되기 때문에 relaxation의 bound가 매우 좋지 않으므로 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;Lagrangian relaxation&lt;/b&gt;을 사용하고자 한다. 

&lt;br /&gt;&lt;br /&gt;
IP 문제를 좀더 간단하게 일반적인 폼 (general form)으로 바꿔보자. 

$$
\begin{aligned}
    &amp;amp;z=\max cx \\
    &amp;amp;Dx \le d  \\
    &amp;amp;x \in X
\end{aligned}
$$

여기서 $Dx \le d $는 $m$개의 복잡한 제약식이다. 

&lt;br /&gt;&lt;br /&gt;

어떤 값 $u = (u_1, ... , u_m) \ge 0$ 에 대해 다음과 같이 IP의 relaxation을 정의하자. 

$$
\begin{aligned}
    \text{(IP(u))} \quad &amp;amp;z(u)=\max cx + u(d-Dx)\\
    &amp;amp;x \in X
\end{aligned}
$$

IP($u$)는 $\{x : Dx \le d, x \in X\} \subseteq X $ 이므로 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;feasibel region&lt;/b&gt;은 같거나 크고, $u \ge 0$ 이고 모든 $x \in X$에 대해 $(d-Dx) \ge 0$이므로 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;목적값(objective value)&lt;/b&gt; 또한 원래 IP 문제보다 같거나 크다. 

&lt;br /&gt;&lt;br /&gt;

IP($u$)에서 복잡한 제약식이 목적함수의 penalty term인 $u(d-Dx)$으로 추가됨으로써 다루어지는 것을 볼 수 있다. 이 때 $u$ 를 $Dx \le d$ 제약에 대한 &lt;i&gt;&lt;b style=&quot;color:#d7385e; &quot;&gt;Lagrange multiplier&lt;/b&gt;&lt;/i&gt; (&lt;i&gt;price&lt;/i&gt;, &lt;i&gt;dual variable&lt;/i&gt;) 라고 한다. 
&lt;br /&gt;&lt;br /&gt;

따라서 IP($u$)를 파라미터 $u$를 가진 IP의 &lt;i&gt;Lagrangian relaxation (subproblem)&lt;/i&gt;이라 부른다. IP($u$)는 IP의 relaxation이기 때문에 $z(u) \ge z$이고 IP의 최적값(opmial value)의 upper bound를 얻을 수 있다. 가장 좋은 upper bound를 찾기 위해 &lt;i&gt;&lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;Lagrangian Dual Problem&lt;/b&gt;&lt;/i&gt;을 푼다. 
&lt;br /&gt;&lt;br /&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/post_img/max_relaxation_bound.png&quot; width=&quot;350&quot; height=&quot;170&quot; /&gt;
&lt;/p&gt;
Lagrangian Dual Problem은 다음과 같이 정의한다. 

$$
\begin{aligned}
    \text{(LD)} \quad &amp;amp;w_{LD}=\min \{z(u) : u \ge 0 \} 
\end{aligned}
$$

Lagrangian relaxation을 풀어 IP의 최적 솔루션을 찾을 수도 있다.
&lt;br /&gt;&lt;br /&gt;

&lt;div style=&quot;border: 0px solid red; text-align: left; margin: 0 auto; width:45% &quot;&gt;
 IF $u \ge 0$, &lt;br /&gt;
1. $x(u)$는 IP($u$)의 &lt;i&gt;optimal solution&lt;/i&gt;이고 &lt;br /&gt;
2. $D(x) \le d$ 이고 &lt;br /&gt;  
3. $u_i &amp;gt; 0$일 경우, $(Dx(u))_i = d_i$&lt;br /&gt;
THEN $x(u)$는 IP의 optimal이다.
&lt;/div&gt;
&lt;br /&gt;
1에 의해 $w_{LD} \le z(u)$이고, 3에 의해 $cx(u)+u(d-Dx(u)) = cx(u)$이다. 2에 의해 $x(u)$는 IP에서 feasible이고 따라서 $cx(u) \le z$ 이다. 그러므로 $w_{LD} \le z(u) = cx(u) \le z$이고 equality 제약으로 인해 $w_{LD} \ge z$이므로 $x(u)$는 IP에서 optimal이다. 
&lt;br /&gt;&lt;br /&gt;
&lt;span style=&quot;font-weight:700; font-size:1.3em;  margin-right: 1em;&quot;&gt;
Application - UFL
&lt;/span&gt;
&lt;br /&gt;&lt;br /&gt;
UFL 문제에 이를 적용해 보자. 먼저, strong formulation으로 시작한다. 
$$
\begin{aligned}
    \text{(IP)} \quad z=\max &amp;amp;\sum_{i \in M} \sum_{j \in N} c_{ij}x_{ij} - \sum_{j \in N} f_j y_j \\
    &amp;amp;\sum_{j \in N} x_{ij} = 1 \quad \forall i \in M  \\
    &amp;amp;x_{ij}-y_j \le 0 \quad \forall i \in M, j \in N \\ 
    &amp;amp;x \in R^{|M|\times|N|}, y \in B^{|N|}
\end{aligned}
$$

demand 제약식을 dualizing한다.
$$
\begin{aligned}
    \text{(IP($u$))} \quad z=\max &amp;amp;\sum_{i \in M} \sum_{j \in N} (c_{ij}-u_i)x_{ij} - \sum_{j \in N} f_j y_j + \sum_{i \in M}u_i \\
    &amp;amp;x_{ij}-y_j \le 0 \quad \forall i \in M, j \in N \\ 
    &amp;amp;x \in R^{|M|\times|N|}, y \in B^{|N|}
\end{aligned}
$$
이는 각 location에 대한 subproblem으로 갈라진다. 
$$
\begin{aligned}
    \text{(IP}_j(u)) \quad z_j(u)=\max &amp;amp;\sum_{i \in M} (c_{ij}-u_i)x_{ij} - f_j y_j \\
    &amp;amp;x_{ij}-y_j \le 0 \quad \forall i \in M \\ 
    &amp;amp;x_{ij} \ge 0 \quad \forall i \in M, y_i \in B^1
\end{aligned}
$$

따라서 $IP_j(u)$이면 $z(u) = \sum_{j \in N} z_j(u) + \sum_{i \in M} u_i$이다. 
만약 $y_j = 0$이면 모든 $i$에 대해 $x_{ij} = 0$이고 목적값은 0이 된다. 만약 $y_j=1$이면 profitable한 모든 고객은 서비스를 받으므로 $c_{ij}-u_i &amp;gt;0$이다. 따라서 $z_j(u) = \max \{0, \sum_{i \in M} \max [c_{ij}-u_i, 0]-f_j\}$이다.
&lt;br /&gt;&lt;br /&gt;
&lt;span style=&quot;font-weight:700; font-size:1.3em;  margin-right: 1em;&quot;&gt;
UFL Example
&lt;/span&gt;

&lt;br /&gt;&lt;br /&gt;
이와 관련된 간단한 예시를 들어보자. $m = 6$인 clients와 $n=5$인 potential locations가 있고 fixed location cost $f = (2,4,5,3,3)$이고 client-location profit matrix($c_{ij}$)는 왼쪽과 같다고 하자. $u=(5,6,3,2,5,4)$라 하면 ($c_{ij}-u_i$)를 오른쪽과 같이 나타낼 수 있다. 
&lt;br /&gt;&lt;br /&gt;

&lt;div style=&quot;display: inline-block; margin-left: 0.5em; margin-right: 0.5em; &quot;&gt;
&lt;img src=&quot;/images/post_img/ex1.png&quot; width=&quot;250&quot; height=&quot;150&quot; /&gt;
&lt;/div&gt;
&lt;div style=&quot;display: inline-block; margin-right: 0.5em; &quot;&gt;
&lt;img src=&quot;/images/post_img/ex2.png&quot; width=&quot;300&quot; height=&quot;150&quot; /&gt;
&lt;/div&gt;
&lt;br /&gt;
모든 $j = 2$에 대해 $y_2=0$이면 0의 값을 얻고 $y_2=1$이면 $x_{22}=1$, $x_{52}=1$로 설정하여 $y_2=1$인 net profit이 7-4 = 3이 된다. 그러므로 $z_2(u)=3$을 주는 $y_2=1$로 설정하는 것이 optimal 이다. 각 depot에 대해 비슷한 계산을 수행하면 IP($u$)의 optimal solution은 $y_1=y_3=y_5=0$, $y_2=x_{22}=x_{52}=1, y_4 = x_{64}=1$로 세팅하면 $z(u) = 3+1+\sum_{i \in M} u_i = 29$ 이다. 

&lt;br /&gt;&lt;br /&gt;
&lt;!-- &lt;span style=&quot;background-color: #f3c623&quot;&gt; --&gt;
&lt;/div&gt;
</description>
        <pubDate>Wed, 15 Apr 2020 18:00:08 +0000</pubDate>
        <link>http://munjeongkang.github.io/IP/</link>
        <guid isPermaLink="true">http://munjeongkang.github.io/IP/</guid>
        
        
        <category>최적화</category>
        
      </item>
    
      <item>
        <title>논문리뷰 - Coordinated logistics with a truck and a drone</title>
        <description>&lt;hr /&gt;

&lt;div style=&quot;font-weight:700; font-size:1.3em; text-align:center;&quot;&gt;Abstract &lt;/div&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div style=&quot;font-weight:500; font-size:1.0em; margin-left: 1em; margin-right: 1em;text-align:justify; &quot;&gt;
We determine the efficiency of a delivery system in which an unmanned aerial vehicle (UAV), or a fleet of UAVs, provides service to customers while making return trips to a truck that is itself moving. In other words, a UAV picks up a package from the truck (which continues on its route), and after delivering the package, the UAV returns to the truck to pick up the next package. Although the hardware for such systems already exists, it is not yet understood to what extent such an approach can actually provide a significantly improved quality of service. By combining a theoretical analysis in the Euclidean plane with real-time numerical simulations on a road network, we conclude that the improvement in efficiency due to introducing a UAV is proportional to the square root of the ratio of the speeds of the truck and the UAV.&lt;br /&gt;&lt;br /&gt;

&lt;/div&gt;

&lt;hr /&gt;

&lt;div style=&quot;font-weight:700; font-size:1.3em; text-align:center;&quot;&gt;Summary
&lt;/div&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;div style=&quot;font-weight:500; font-size:1.0em; margin-left: 1em; margin-right: 1em;text-align:justify; &quot;&gt;

이 논문은 드론과 같은 무인항공기와 트럭을 함께 사용하는 배달 시스템의 효율성을 판단한다. 유클리드 평면의 이론적 분석과 도로망에서의 실시간 시뮬레이션을 결합하여 무인항공기 도입에 따른 효율 향상은 트럭과 무인항공기의 속도 비율의 제곱근에 비례한다는 것이 결론이다. 

&lt;/div&gt;

&lt;hr /&gt;

&lt;div style=&quot;font-weight:700; font-size:1.3em; text-align:center;&quot;&gt;본문 내용
&lt;/div&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;div style=&quot;font-weight:500; font-size:1.0em; margin-left: 1em; margin-right: 1em;text-align:justify;  &quot;&gt;

최근 교통과 물류에서 가장 많이 언급되는 것 중 하나가 &lt;b style=&quot;color:#d7385e; font-size:1.2&quot;&gt;드론의 잠재적인 사용&lt;/b&gt;에 관한 것이다. 특히 배송 시스템에 드론을 많이 활용하고자 하는데 아마존의 Amazon Prime Air, 구글의 Project Wing, DHL의 Parcelcopter 등을 예시로 들 수 있다. 
&lt;br /&gt;&lt;br /&gt;

&lt;/div&gt;

&lt;div style=&quot;border:0px solid red; float: left; width:30%; box-sizing : border-box;  margin-left: 1em;&quot;&gt; &lt;img src=&quot;/images/post_img/amazon_prime_air.jpg&quot; width=&quot;250&quot; height=&quot;150&quot; /&gt; &lt;p align=&quot;center&quot;&gt;Amazon Prime Air&lt;/p&gt;
&lt;/div&gt;
&lt;div style=&quot;border:0px solid green; float: left; margin-left:2.5%; margin-right: 2%; width:30%; box-sizing : border-box&quot;&gt; &lt;img src=&quot;/images/post_img/Google-Project-Wing.jpg&quot; width=&quot;250&quot; height=&quot;150&quot; /&gt;&lt;p align=&quot;center&quot;&gt;Project Wing&lt;/p&gt;
&lt;/div&gt;
&lt;div style=&quot;border:0px solid blue; float: right; width:30%; box-sizing : border-box; margin-right: 1em;&quot;&gt; &lt;img src=&quot;/images/post_img/parcel.jpg&quot; width=&quot;250&quot; height=&quot;150&quot; /&gt;&lt;p align=&quot;center&quot;&gt;Parcelcopter&lt;/p&gt;
&lt;/div&gt;
&lt;div&gt;

&lt;div style=&quot;font-weight:500; font-size:1.0em; margin-left: 1em; margin-right: 1em;text-align:justify; text-indent:0%; &quot;&gt;

여기서 last-mile delivery의 수요가 증가할 것이라는 언급이 있다. 라스트 마일이란 상품이 최종 목적지까지 배송되기 위한 과정으로 상품을 개인 소비자에게 직접 전달하기 위한 배송 마지막 구간을 의미한다. 즉, 무인정찰기를 배송시스템에 도입하여 하늘과 도로를 통해 배송함으로써 차세대 물류 시스템을 수행할 것이라는 전망이다. 무인항공기 기반 배송 시스템은 장단점이 명백하게 있는데 일단 드론은 운송 비용이 낮고 사람의 개입없이 운행할 수 있으며 도로 교통에 영향을 받지 않기 때문에 빠르게 운행할 수 있다. 그러나 운반 용량이 매우 작고 이동 반경이 짧으며 충전을 자주 해야한다. 

&lt;br /&gt;&lt;br /&gt;
&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/post_img/fig1.png&quot; width=&quot;600&quot; height=&quot;300&quot; /&gt;
&lt;/p&gt;
위의 그림은 트럭으로만 배달한 경우, 드론으로만 배달한 경우, 트럭과 드론으로 배달한 경우의 배송경로를 나타낸다. 드론은 트럭의 속도보다 약 4배 정도 빠르다고 가정하였고 (c)에서 볼 수 있듯이 어느 한 가지로 배송하는 것과는 배송 경로의 차이가 있음을 알 수 있다. 
&lt;br /&gt;&lt;br /&gt;

이 논문의 목적은 &lt;b style=&quot;color:#d7385e; font-size:1.2&quot;&gt;드론과 트럭을 함께 사용하여 배송하는 것의 효율성을 판단&lt;/b&gt;하는 것이다. 이러한 실제 시스템 중 하나가 HorseFly이다. 실제로 어느 정도까지 서비스 품질을 향상시킬 수 있는지 파악되지 않았기 때문에 수학적으로 얼마나 개선을 실현시킬 수 있는지 언급한다. 
&lt;br /&gt;&lt;br /&gt;
&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/post_img/horsefly.png&quot; width=&quot;450&quot; height=&quot;280&quot; /&gt;
&lt;/p&gt;
이는 TSP의 일반적인 경우이므로 최적으로 풀기 매우 어렵다. 그러므로 문제를 작은 파라미터 집합으로 줄이고 이러한 파라미터가 문제의 결과에 어떻게 영향을 미치는지 결정한다. 고객은 유클리드 평면에서 확률 밀도에 따라 분포한다고 가정한다. 이 논문은 특정 문제 사례에 대한 것보다는 인구 밀도에 따라 한 지역에서 많은 고객이 서비스를 받을 때 장기적인 행동에 대해 신경을 쓴다. 본질적으로 VRP 모델의 사례로 생각할 수 있다. &lt;b style=&quot;color:#d7385e; font-size:1.2&quot;&gt;서로 정반대되는 장단점을 가진 두 종류의 차량을 최적으로 조정하는 문제&lt;/b&gt;로 생각할 수 있다. 
&lt;br /&gt;&lt;br /&gt;
$n$개의 고객이 있다고 가정하며 트럭의 속도는 $\phi_0$, 드론의 속도는 $\phi_1$로 나타낸다. ($\phi_0&amp;lt;\phi_1$) compact planar region을 $\mathcal{R}$, $\mathcal{R}$에서의 loop를 $\mathcal{L}$, 모든 loop $\mathcal{L}$의 집합을 Loop($\mathcal{R}$)이라 하면 $d(x, \mathcal{L})$를 다음과 같이 $x$와 loop $\mathcal{L}$ 사이의 거리로 나타낼 수 있다. 
$$
d(x, \mathcal{L})=\min _{x^{\prime} \in \mathcal{L}}\left\|x-x^{\prime}\right\|
$$
이는 일반적인 유클리드 거리를 나타내고 {1,...$n$}의 순열 집합을 $S_n (\sigma \in S_n)$이라 하면 항공기에서 집합 $S$의 $\epsilon$-neighborhood는 다음과 같이 $N_{\epsilon}(\mathcal{S})$로 쓰인다. 
$$
N_{\epsilon}(\mathcal{S})=\left\{x \in \mathbb{R}^{2}: \min _{x^{\prime} \in \mathcal{S}}\left\|x-x^{\prime}\right\| \leq \epsilon\right\}
$$
먼저 앞서 언급한 &lt;i&gt;horsefly routing problem&lt;/i&gt;을 공식적으로 정의한다. 트럭 1대와 드론 1대에 대해 $p_1,...,p_n$을 포인트의 집합이라 한다면 다음을 만족하는 최적 솔루션이 $p_1,...,p_n$의 최적 &lt;i&gt;horsefly tour&lt;/i&gt;이다. 

&lt;p align=&quot;right&quot;&gt;
&lt;img src=&quot;/images/post_img/eq1.png&quot; width=&quot;600&quot; height=&quot;80&quot; /&gt;
&lt;/p&gt;

아래 그림은 $p_1,...p_6$의 지점에 대해 $\phi_1/\phi_0=3/2$ 인 문제와 $\phi_1/\phi_0=3$인 문제의 horsefly 경로 문제의 솔루션이다. $x_1$을 임의의 출발점으로 정의하면, 두 경로 모두 $\sigma = {1,3,5,2,6,4}$이다. 
&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/post_img/fig2.png&quot; width=&quot;550&quot; height=&quot;260&quot; /&gt;
&lt;/p&gt;
$\mathcal{L}$의 $\epsilon$-neighborhood는 Route의 내부(inner) 부분인 $R_{\text{in}}$와  외부(outer) 부분인 $R_{\text{out}}$을 가진다. 아래 그림의 (a)는 $R_{\text{in}}$과 $R_{\text{out}}$을 나타낸다. 색칠된 부분과 빗금친 부분이 모두 $R_{\text{out}}$이므로 면적 Area($R_{\text{out}}$) = $\pi \epsilon^{2}+\epsilon \ell$, 둘레  perimeter($R_{\text{out}}$) = $\ell + 2\pi\epsilon$이다. (b)는 내부 loop $\mathcal{L}_\epsilon^{\prime}$ 과 모든 $\epsilon^{\prime}$에 대해 $R_{\mathrm{out}}^{\prime} \subseteq R_{\mathrm{in}}$ 임을 보여준다. 
&lt;br /&gt;&lt;br /&gt;
&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/post_img/fig3.png&quot; width=&quot;550&quot; height=&quot;260&quot; /&gt;
&lt;/p&gt;
아래 그림의 (a)와 (b)는 loop $\mathcal{L}$을 가지는 지역 $\mathcal{R}$을 통과하는 지그재그(zig-zagging) 모양과 나선형(spiralling)모양의 투어를 나타낸다. 수요 밀도가 불균등(non-uniform)일 때, (c)와 (d)에서 같이 최적 loop는 밀도가 더 높은 지역에 집중되어야 한다.  
&lt;br /&gt;&lt;br /&gt;
&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/post_img/fig4.png&quot; width=&quot;650&quot; height=&quot;200&quot; /&gt;
&lt;/p&gt;
아래 그림에는 $N$=16인 사각형 패치 $\mathcal{P}_i$가 있다. (a)와 (b)는 하나의 loop를 패치의 모양에만 의존하는 방식으로 항상 다수의 loop로 분해할 수 있음을 보여준다. (c)와 (d) 또한, 패치의 모양에만 의존하는 방식으로 하나의 loop로 loop들의 집합을 항상 결합할 수 있음을 보여준다.

&lt;br /&gt;&lt;br /&gt;
&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/post_img/fig5.png&quot; width=&quot;650&quot; height=&quot;200&quot; /&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
[참고] &lt;i&gt;Claim&lt;/i&gt;9. 위의 식 (1)의 lower bound가 문제의 최적 목적 값이다. 
&lt;img src=&quot;/images/post_img/eq2.png&quot; width=&quot;500&quot; height=&quot;60&quot; /&gt;
&lt;/p&gt;
아래 그림은 &lt;i&gt;Claim&lt;/i&gt;9의 스케치이다. (a)와 같이 문제(1)의 솔루션에서 시작하고 (b)와 같이 $x_i^{\prime}$이 구성된다. 그리고 나서 (c)처럼 $x_i^{\prime}$들을 통해 투어를 얻는다. 
&lt;br /&gt;&lt;br /&gt;
&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/post_img/fig6.png&quot; width=&quot;650&quot; height=&quot;200&quot; /&gt;
&lt;/p&gt;
이 논문에서는 2가지 계산 실험을 하는데 첫 번째 실험은 계수 $\alpha$(논문의 (12)와 (???)에서 사용됨)를 추정하기 위해 사용하는 균일하게 분포된 수요를 가지는 unit square에서 이루어진다. 두 번째 실험에서는 $\alpha$의 추정치를 사용하여 균일하지 않은 분포에 따른 수요와 도로망에서의 실시간 주행 정보가 사용될 때의 효율성 향상에 대해 예측을 한다. 아래 그림은 두 개의 다른 horsefly 투어를 나타낸다. (a)는 $k$=1, $\phi_1$=1.5이고 (b)는 $k$=3, $\phi_1$=3이다. (여기서 $k$는 무인항공기의 개수이다.) $p_i$의 다른 색깔 (검정, 회색, 흰색)은 3개의 무인항공기 중 어느 것이 해당 지역을 방문하는지를 나타낸다. 
&lt;br /&gt;&lt;br /&gt;
&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/post_img/fig7.png&quot; width=&quot;550&quot; height=&quot;280&quot; /&gt;
&lt;/p&gt;
아래 그림에서 (a)는 캘리포니아(California) 주 패서디나(Pasadena)의 지도를 보여주고 (b)는 패서디나에 위치한 모든 1734 인구조사(census) 블록의 중심으로 구성된 초기 데이터 집합을 보여준다. (c)는 그 중심에서 샘플링한 $n$=25인 지점의 도로망에 대한 TSP 투어를 나타내고 (d)는 2단계 휴리스틱(논문 4.1참고)을 사용하여 계산한 horsefly tour를 보여준다. 
&lt;br /&gt;&lt;br /&gt;
&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/post_img/fig8.png&quot; width=&quot;750&quot; height=&quot;400&quot; /&gt;
&lt;/p&gt;
아래 12개 차트는 각각 특정한 수의 고객 $n$과 무인항공기 속도 $\phi_1$에 대해 수행한 실험이다. 
검은색 막대는 트럭 한 대가 $n$개의 고객을 방문하는 데 걸리는 시간(시간)을 나타낸다. 회색 막대는 트럭과 무인항공기가 horsefly 투어를 할 것으로 예상되는 시간을 나타낸다. 흰색 바는 트럭과 무인정찰기가 horsefly 투어를 수행하는 데 소요되는 실제 시간을 나타낸다.

&lt;br /&gt;&lt;br /&gt;
&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/post_img/fig9.png&quot; width=&quot;750&quot; height=&quot;400&quot; /&gt;
&lt;/p&gt;
아래 차트는 무인항공기 개수 $k$와 속도 $\phi_1$에 대해 수행한 실험이다. 
&lt;br /&gt;&lt;br /&gt;
&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/post_img/fig10.png&quot; width=&quot;750&quot; height=&quot;400&quot; /&gt;
&lt;/p&gt;
실험 결과 트럭만 사용하는 것보다 &lt;b style=&quot;color:#d7385e; font-size:1.2&quot;&gt;트럭과 무인항공기를 동시에 사용했을 때 시간이 더 적게 걸리는 것&lt;/b&gt;을 확인할 수 있다. 
&lt;br /&gt;&lt;br /&gt;
논문 결과는 다음과 같이 정리할 수 있다. 
&lt;ul&gt;

&lt;li&gt;무인항공기와 트럭 배달의 효율성은 각각의 &lt;b style=&quot;color:#d7385e; font-size:1.2&quot;&gt;속도 비율의 제곱근에 비례&lt;/b&gt;한다.&lt;/li&gt;
&lt;li&gt;True globally 최적 솔루션이 아니라 트럭과 무인항공기 사이의 조정된 경로를 계산하기 위해 &lt;b style=&quot;color:#d7385e; font-size:1.2&quot;&gt;휴리스틱한 방법&lt;/b&gt;을 사용함.(분석의 weak point 중 하나)&lt;/li&gt;
&lt;li&gt;이 논문에서 제시된 문제에 대한 솔루션을 찾는 테크닉을 현재까지 알지 못하지만, 물류에 대한 무인항공기의 관심이 증가함에 따라 향후 몇 년 내에 그러한 기술들이 가능할 것으로 예상함.&lt;/li&gt;
&lt;/ul&gt;

&lt;/div&gt;
&lt;hr /&gt;


&lt;div style=&quot;font-weight:700; font-size:1.3em; text-align:center;&quot;&gt;Cite
&lt;/div&gt;
&lt;br /&gt;
&lt;span style=&quot;font-weight:500; font-size:1.0em; margin-left: 1em; margin-right: 1em;text-align:justify; text-indent:0%; font-family: Times New Roman; &quot;&gt;
Carlsson, J. G., &amp;amp; Song, S. (2018). Coordinated logistics with a truck and a drone. &lt;i&gt;Management Science, 64&lt;/i&gt;(9), 4052-4069.
&lt;/span&gt;
&lt;span style=&quot;font-weight:400; font-size:1.0em;&quot;&gt;
&lt;a href=&quot;https://pdfs.semanticscholar.org/23a4/3524fd5168acfd589e919c143f49a6eeeac3.pdf&quot;&gt; 논문 링크 &lt;/a&gt;
&lt;/span&gt;

&lt;!-- &lt;span style=&quot;background-color: #f3c623&quot;&gt; --&gt;
&lt;/div&gt;
</description>
        <pubDate>Mon, 13 Apr 2020 18:00:08 +0000</pubDate>
        <link>http://munjeongkang.github.io/%E1%84%82%E1%85%A9%E1%86%AB%E1%84%86%E1%85%AE%E1%86%AB%20%E1%84%85%E1%85%B5%E1%84%87%E1%85%B22/</link>
        <guid isPermaLink="true">http://munjeongkang.github.io/%E1%84%82%E1%85%A9%E1%86%AB%E1%84%86%E1%85%AE%E1%86%AB%20%E1%84%85%E1%85%B5%E1%84%87%E1%85%B22/</guid>
        
        
        <category>논문리뷰</category>
        
      </item>
    
      <item>
        <title>인공신경망 - Recommender Systems</title>
        <description>&lt;hr /&gt;
&lt;div style=&quot;font-weight:500; font-size:1.0em; margin-left: 1em; margin-right: 1em;text-align:justify; &quot;&gt;
정보 기술 분야에서 머신러닝의 주요한 응용분야 중 하나는 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;잠재 고객에게 아이템을 추천하는 것&lt;/b&gt;이다. 이를 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;온라인 광고&lt;/b&gt;와 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;아이템 추천&lt;/b&gt; 두 가지 타입으로 구분할 수 있다. 둘 다 사용자와 아이템 간의 연관성을 예측하는데 의존하며, 광고가 표시되거나 해당 아이템에 대한 추천이 사용자에게 제시될 경우 어떤 행동의 확률이나 기대되는 이득을 예측한다. 때떄로, 추천은 제품을 실제로 팔기 위한 목적이 아닌 소셜 네트워크 뉴스 피드에 표시할 게시물을 선택하거나 영화 추천, 농담 추천, 전문가의 조언 추천, 비디오 게임 플레이어 매칭, 데이트 서비스 매칭 등에 관한 것일 수 있다. 
&lt;br /&gt;&lt;br /&gt;
이것과 연관된 문제는 감독(supercised)학습 문제처럼 처리된다. 아이템과 사용자에 대한 정보가 주어지면 관심의 프록시(proxy)를 예측하기 때문이다. 이는 종종 회귀분석(조건부 기댓값을 예측) 또는 확률적 분류 문제(discrete한 사건의 조건부 확률을 예측)로 해결한다. 추천자 시스템에 대한 초기 작업은 이러한 예측을 위해 사용자 ID와 아이템 ID 같은 최소한의 인풋 정보에 의존했다. 이런 맥락에서 일반화하는 유일한 방법은 다른 사용자나 다른 아이템에 대한 타겟 변수값의 패턴간 유사성에 의존하는 것이다. 
&lt;br /&gt;&lt;br /&gt;
이 원리에 기초한 알고리즘이 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;collaborate filtering&lt;/b&gt; 이다. 비모수적 접근법과 모수적 방법 모두 가능하다. 모수적 방법은 각 사용자와 아이템에 대한 분포적인 표현(임베딩(embedding)으로 불린다.)을 학습하는데 의존한다. 예측은 다음과 같이 사용자 임베딩과 아이템 임베딩 (사용자 ID나 아이템 ID 중 하나에 의존하는 상수에 의해 수정될 가능성이 있다.) 사이의 내적을 통해 구한다. 

$$
\hat{R}_{u, i}=b_{u}+c_{i}+\sum_{j} A_{u, j} B_{j, i}
$$

Collaboratice filtering 시스템은 기본적인 제한이 있다. 새로운 아이템이나 사용자가 도입되면, 기록이 없기 때문에 다른 아이템이나 사용자와의 유사성 또는 새로운 사용자와 기존 아이템 사이의 연관성의 정도를 평가할 방법이 없다는 것이다. 이를 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;cold-start &lt;/b&gt;recommendations 문제라고 부른다. 콜드 스타트 추천 문제를 해결하는 일반적인 방법은 개별적인 사용자와 아이템에 대해 추가적인 정보를 도입하는 것이다. 예를 들어 추가적인 정보는 사용자 프로필 정보나 각 아이템의 특징이 될 수 있다. 이와 같은 정보를 사용하는 시스템을 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;content-based recommender&lt;/b&gt; 시스템이라고 한다. 풍부한 사용자 특징이나 아이템 특징의 집합에서 임베딩으로 매핑(mapping)하는 것은 딥러닝 구조(architecture)를 통해 학습될 수 있다. 
&lt;/div&gt;
</description>
        <pubDate>Sun, 12 Apr 2020 18:00:08 +0000</pubDate>
        <link>http://munjeongkang.github.io/ANN10/</link>
        <guid isPermaLink="true">http://munjeongkang.github.io/ANN10/</guid>
        
        
        <category>수업</category>
        
      </item>
    
      <item>
        <title>인공신경망 - Challenge of Long-Term Dependencies</title>
        <description>&lt;hr /&gt;
&lt;div style=&quot;font-weight:500; font-size:1.0em; margin-left: 1em; margin-right: 1em;text-align:justify; &quot;&gt;

순환(recurrent) 네트워크에서 long-term dependencies를 학습하는 기본적인 문제는 여러 단계에 걸쳐 전파되는 기울기가 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;사라지거나(vanish)) 폭발하는(explode)&lt;/b&gt; 경향이 있다는 것이다. 대부분의 경우 vanish 문제이고 explode 문제는 드물지만 최적화에 더 어려움을 준다. 순환 관계를 다음과 같이 비선형 활성화 함수와 인풋 $x$가 없는 매우 단순한 순환 신경망으로 생각할 수 있다. 

$$
\boldsymbol{h}^{(t)}=\boldsymbol{W}^{\top} \boldsymbol{h}^{(t-1)}
$$

이를 다음과 같이 단순화할 수 있다. 

$$
\boldsymbol{h}^{(t)}=\boldsymbol{(W^t)}^{\top} \boldsymbol{h}^{(0)}
$$

만약 $\boldsymbol{W}$가 eigendecomposition이면 순환성(recurrence)은 더 단순화될 수 있다.

$$
\boldsymbol{h}^{(t)}=\boldsymbol{Q}^{\top} \Lambda^t \boldsymbol{Q} \boldsymbol{h}^{(0)}
$$

고유값이 $t$승으로 상승하는 것은 크기(magnitude)가 1보다 작은 고유값은 0으로 감소하고 1보다 큰 고유값은 explode되도록 유발한다. 가장 큰 고유벡터로 정렬되지 않은 $\boldsymbol{h}^{(0)}$의 성분은 결국에는 버려질 것이다. 
&lt;br /&gt;&lt;br /&gt;

만약 각 time step마다 가중치가 다른 $w^{(t)}$를 가지는 비순환적 네트워크를 만들면 상황이 달라진다. 초기 상태가 1로 주어진다면, 시간 $t$에서 상태는 $\prod_{t}w^{(t)}$로 주어진다. 평균이 0이고 분산이 $v$값을 가지는 서로 독립인 $w^{(t)}$값이 랜덤하게 생성된다고 가정하면 산출물(product)의 분산은 $O(v^n)$이다. 원하는 분산 $v^*$를 얻기 위해 분산 $v=\sqrt[n]{v^*}$를 가지는 개별적인 가중치를 선택할 수 있다. 따라서 신중하게 선택한 스케일링을 가지는 매우 깊은 feedforward networks는 vanishing 과 exploding gradient problem을 피할 수 있다. 
&lt;br /&gt;&lt;br /&gt;
모델이 long-term dependencies가 나타날 수 있을 때마다 long-term interaction의 기울기는 short-term interaction의 기울기보다 기하급수적으로 더 작은 크기를 가진다. 이러한 의존성 대한 신호는 short-term dependencies에서 발생하는 가장 작은 변동(fluctuations)에 의해 숨겨지는 경향이 있기 때문에 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;long-term dependencies를 학습하는데 오랜 시간이 걸릴 수 있다.&lt;/b&gt; 
&lt;br /&gt;&lt;br /&gt;
포착해야하는 의존성의 범위가 증가함에 따라 gradient-based optimization은 점점 어려워진다. SGD를 통한 전통적인 RNN의 성공적인 트레이닝 확률이 연속적인 길이가 길어지면 (10 또는 20 등) 0에 빠르게 도달하기 때문이다. 
&lt;/div&gt;
</description>
        <pubDate>Sun, 12 Apr 2020 18:00:08 +0000</pubDate>
        <link>http://munjeongkang.github.io/ANN09/</link>
        <guid isPermaLink="true">http://munjeongkang.github.io/ANN09/</guid>
        
        
        <category>수업</category>
        
      </item>
    
      <item>
        <title>인공신경망 - Motivation</title>
        <description>&lt;hr /&gt;

&lt;div style=&quot;font-weight:500; font-size:1.0em; margin-left: 1em; margin-right: 1em;text-align:justify; &quot;&gt;

Convolution은 머신러닝 시스템을 향상시킬 수 있는 세 가지 중요한 아이디어를 활용한다. 각각은 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;sparse interactions&lt;/b&gt;, &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;parameter sharing&lt;/b&gt;, &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;equivariant representations&lt;/b&gt; 이다. 컨볼루션 네트워크는 주로 sparse interaction을 가진다. sparse interaction은 sparse connectivity 또는 sparse weights라고도 한다. 이것은 커널(kernel)을 인풋보다 작게 함으로써 이루어진다. 즉, 더 적은 파라미터를 저장해야한다는 의미이다. 또한, 아웃풋을 계산하기위해 더 적은 작업(operations)이 요구된다는 것이다. 
&lt;br /&gt;&lt;br /&gt;

&lt;div style=&quot;border: 1px; float: right;margin-left: 1em; margin-right: 1em; &quot;&gt;
&lt;img src=&quot;/images/post_img/AN13.png&quot; width=&quot;290&quot; height=&quot;300&quot; /&gt;
&lt;/div&gt;
&lt;div style=&quot;border: 1px; margin-left: 1em; margin-right: 1em; &quot;&gt;
&lt;img src=&quot;/images/post_img/AN12.png&quot; width=&quot;290&quot; height=&quot;300&quot; /&gt;
&lt;/div&gt;
&lt;br /&gt;
아래 오른쪽의 이미지는 원본 사진의 각 픽셀을 취해 왼쪽의 인접 픽셀의 값을 빼면서 만들어졌다. 두 이미지 모두 280 픽셀이며 입력 이미지는 320 픽셀인 반면 출력 이미지는 319 픽셀이다. 이 변환은 두 개의 요소를 포함하는 컨볼루션 커널로 설명될 수 있고 319*280*3 = 267,960의 floating-point(부동 소수점, CPU의 성능을 수치로 나타낼 때 사용되는 단위) 연산이 요구된다. 행렬곱으로 동일한 변환을 설명하려면 320*280*319*280 또는 80억 이상의 entries가 필요하다. 
&lt;br /&gt;&lt;br /&gt;
&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/post_img/AN14.png&quot; width=&quot;450&quot; height=&quot;280&quot; /&gt;
&lt;/div&gt;
&lt;br /&gt;
parameter sharing의 특정한 형태는 레이어가 해석(translation)에 동일성(equivariance)이라 불리는 특성을 갖도록 한다. 함수가 동일하다고 말하는 것은 입력이 바뀌면 출력이 같은 방식으로 바뀐다는 것을 의미한다. 구체적으로 함수 $f(x)$는 $f(g(x)) = g(f(x))$이라면 함수 $g$와 동일하다. convolution의 경우 만약 $g$가 인풋을 해석하는 어떤 함수라면 convolution 함수는 $g$와 동일해진다. 만약 인풋에 있는 객체를 움직이면, 인풋의 representation은 아웃풋에서 같은 양만큼 움직일 것이다. 그러나 Convolution은 이미지의 크기(scale) 변화나 회전 등의 변형과는 동일시 되지 않는다. 

&lt;/div&gt;
</description>
        <pubDate>Sun, 12 Apr 2020 18:00:08 +0000</pubDate>
        <link>http://munjeongkang.github.io/ANN08/</link>
        <guid isPermaLink="true">http://munjeongkang.github.io/ANN08/</guid>
        
        
        <category>수업</category>
        
      </item>
    
      <item>
        <title>인공신경망 - Basic Algorithms</title>
        <description>&lt;hr /&gt;

&lt;div style=&quot;font-weight:500; font-size:1.0em; margin-left: 1em; margin-right: 1em;text-align:justify; &quot;&gt;
&lt;span style=&quot;font-weight:700; font-size:1.3em;  margin-right: 1em;&quot;&gt;
Stochastic Gradient Descent
&lt;/span&gt;
&lt;br /&gt;&lt;br /&gt;
Stochastic Gradient Descent(SGD)와 그 변형들은 머신러닝과 특히 딥러닝에서 가장 많이 사용된 최적화 알고리즘이다.
&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/post_img/AN10.png&quot; width=&quot;580&quot; height=&quot;300&quot; /&gt;
&lt;/p&gt;

SGD 알고리즘의 가장 중요한 파라미터는 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;learning rate&lt;/b&gt;이다. 실제로 시간이 지나면서 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;점차 learning rate를 줄일 필요&lt;/b&gt;가 있다. SGD 기울기 추정은 최소에 도달해도 사라지지(vanish) 않는 noise($m$개의 트레이닝 예제의 랜덤 샘플링)를 도입하기 때문이다. 실제로 흔히 반복(iteration) $\tau$ 까지 learning rate는 선형적으로 감소(decay)한다.
$$
\epsilon_{k}=(1-\alpha) \epsilon_{0}+\alpha \epsilon_{\tau}
$$
여기서 $\alpha=k/\tau$ 이고, 반복 $\tau$ 후 $\epsilon$은 상수로 남기는 것이 일반적이다. 
&lt;br /&gt;&lt;br /&gt;
learning rate는 시행착오(trial and error)를 통해 선택될 수 있지만 주로 시간의 함수로써 목적함수의 plot인 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;학습 곡선(curves)을 모니터링&lt;/b&gt;함으로써 선택하는 것이 가장 좋다. 선형 스케쥴을 사용할 때, 선택할 파라미터는 $\epsilon_{0}, \epsilon_{\tau}, \tau$ 이다. 일반적으로 $\tau$는 트레이닝 셋을 통해 수백번 통과하는데 필요한 반복 횟수로 설정되고 $\epsilon_{\tau}$는 $\epsilon_{0}$의 약 1%로 설정해야 한다. 
&lt;br /&gt;&lt;br /&gt;
그렇다면 $\epsilon_{0}$(초기 learning rate)은 어떻게 설정해야할까? 값이 너무 크면 학습 곡선이 격렬한(violent) 움직임(oscillations)을 보이고 비용 함수는 상당히 증가할 것이다. 반면 learning rate가 너무 낮으면 학습이 느리게 진행되고 초기 learning rate가 너무 낮으면 학습이 높은 비용값에 머무른다. 일반적으로 최적의 초기 learning rate는 처음 100번 정도 반복 후 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;가장 좋은 값을 내는 learning rate 보다는 높다.&lt;/b&gt; 그러므로 처음 몇 번의 반복을 모니터링하여 가장 좋은 learning rate보다 높은 값을 사용하지만 너무 높은 값은 심한 불안정을 초래하므로 적당한 값을 사용해야한다.  
&lt;br /&gt;&lt;br /&gt;
SGD와 관련된 미니배치 또는 online gradient-based optimization의 가장 중요한 특성은 업데이트당 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;계산 시간이 트레이닝 예제 수에 따라 증가하지 않는다&lt;/b&gt;는 것이다. 이는 심지어 트레이닝 예제의 수가 매우 커져도 수렴할 수 있음을 시사한다. 충분히 큰 데이터셋의 경우, SGD는 전체 트레이닝 셋을 처리하기 전에 마지막 테스트셋 에러의 일정한 허용오차(tolerance)이내로 수렴할 것이다. 
&lt;br /&gt;&lt;br /&gt;
SGD가 convex 문제에 적용될 때, 초과(excess) 에러는 $k$번 반복 후 $O(1/\sqrt{k})$ 이고, strongly convex인 경우 $O(1/k)$이다. Batch gradient descent는 이론상 SGD보다 수렴률이 더 높다. 그러나 $\text { Cramér-Rao }$는 일반화 에러가 $O(1/k)$보다 빨리 감소할 수 없다고 주장하고 있다. 큰 데이터셋을 가지는 SGD는 매우 적은 예제에 대해 기울기를 평가하면서 빠르게 초기 진행이 이루어지는 능력은 그것의 slow 수렴근사보다 더 크다. 학습과정동안 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;미니패치 사이즈를 점점 증가시킴으로써&lt;/b&gt; 배치와 SGD의 이점을 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;trade off&lt;/b&gt; 할 수 있다. 
&lt;br /&gt;&lt;br /&gt;
&lt;span style=&quot;font-weight:700; font-size:1.3em;  margin-right: 1em;&quot;&gt;
Momentum
&lt;/span&gt;
&lt;br /&gt;&lt;br /&gt;
SGD가 유명한 최적화 방법으로 남아있지만 이를 통한 학습은 간혹 느리게 진행될 수 있다. momentum 방법(Polyak,1964)은 특히 높은 곡률(curvature), 작지만 일정한 기울기 또는 noisy 기울기를 갖는 학습을 가속화하기 위해 설계되었다. 모멘텀 알고리즘은 이전 기울기들이 기하급수적으로 감소하는 이동 평균을 누적하여 그 방향으로 계속 움직인다. 
&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/post_img/AN11.png&quot; width=&quot;350&quot; height=&quot;320&quot; /&gt;
&lt;/p&gt;
모멘텀 알고리즘은 변수 $v$를 속도(velocity) 역할로 도입한다. 속도는 음의 기울기가 기하급수적으로 감소하는 평균으로 설정된다. 물리학에서 모멘텀은 질량 시간 속도이다. 모멘텀 학습 알고리즘에서 단위 질량을 가정하므로 속도 벡터 $v$도 입자의 모멘텀으로 간주될 수 있다. 업데이트 룰은 다음과 같다. 

$$
\begin{array}{l}\boldsymbol{v} \leftarrow \alpha \boldsymbol{v}-\epsilon \nabla_{\boldsymbol{\theta}}\left(\frac{1}{m} \sum_{i=1}^{m} L\left(\boldsymbol{f}\left(\boldsymbol{x}^{(i)} ; \boldsymbol{\theta}\right), \boldsymbol{y}^{(i)}\right)\right) \\ \boldsymbol{\theta} \leftarrow \boldsymbol{\theta}+\boldsymbol{v}\end{array}
$$

이제 step의 사이즈는 일련의 기울기가 얼마나 크고 얼마나 정렬되었는지에 따라 달라진다. 스텝 사이즈는 연속적인 기울기 포인트가 정확하게 같은 방향일 때 가장 크다. 만약 모멘텀 알고리즘이 항상 기울기 $g$를 관찰한다면 최종(terminal) 속도에 도달할 때까지 $-g$ 방향으로 가속화될 것이다. 각 스텝의 사이즈는 다음과 같다.  

$$
\frac{\epsilon\|\boldsymbol{g}\|}{1-\alpha}
$$

흔히 실제 사용되는 $\alpha$의 값은 0.5, 0.9, 0.99이다. learning rate와 마찬가지로 $\alpha$도 시간이 지남에 따라 맞춰진다. 

&lt;br /&gt;&lt;br /&gt;
&lt;span style=&quot;font-weight:700; font-size:1.3em;  margin-right: 1em;&quot;&gt;
Nesterov Momentum
&lt;/span&gt;
&lt;br /&gt;&lt;br /&gt;

Sutskever et al.(2013)은 모멘텀 알고리즘의 변형을 다음과 같이 제안했다. 

$$
\begin{array}{l}\boldsymbol{v} \leftarrow \alpha \boldsymbol{v}-\epsilon \nabla_{\boldsymbol{\theta}}\left[\frac{1}{m} \sum_{i=1}^{m} L\left(\boldsymbol{f}\left(\boldsymbol{x}^{(i)} ; \boldsymbol{\theta}+\alpha \boldsymbol{v}\right), \boldsymbol{y}^{(i)}\right)\right] \\ \boldsymbol{\theta} \leftarrow \boldsymbol{\theta}+\boldsymbol{v}\end{array}
$$

Nesterov 모멘텀과 표준 모멘텀의 차이는 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;어디서 기울기가 평가되는가&lt;/b&gt; 이다. Nesterov 모멘텀은 현재 속도가 적용된 후에 기울기가 평가된다. 따라서 Nesterov 모멘텀은 표준 모멘텀 방법에 보정(correction) 요소를 추가하려는 것으로 해석할 수 있다. convex batch gradient의 경우 Nesterov 모멘텀은 초과 에러의 수렴율을 $O(1/k)$ 에서 $O(1/k^2)$로 가져온다. 안타깝게도 SGD에서 Nesterov 모멘텀은 수렴율을 향상시키지 않는다. 
&lt;/div&gt;
</description>
        <pubDate>Sun, 12 Apr 2020 18:00:08 +0000</pubDate>
        <link>http://munjeongkang.github.io/ANN07/</link>
        <guid isPermaLink="true">http://munjeongkang.github.io/ANN07/</guid>
        
        
        <category>수업</category>
        
      </item>
    
      <item>
        <title>인공신경망 - Batch and Minibatch Algorithms</title>
        <description>&lt;hr /&gt;

&lt;div style=&quot;font-weight:500; font-size:1.0em; margin-left: 1em; margin-right: 1em;text-align:justify; &quot;&gt;
머신러닝을 위한 최적화 알고리즘은 일반적으로 전체 비용 함수의 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;일부&lt;/b&gt;만 사용하여 추정된 비용 함수의 기대값에 기초하여 파라미터에 대한 각각의 업데이트를 계산한다. 최적화 알고리즘의 대부분에서 사용되는 목적함수 $J$의 성질도 트레이닝셋에 대한 기대(expextations)이다. 가장 일반적으로 사용되는 성질은 gradient이다. 
$$
\nabla_{\boldsymbol{\theta}} J(\boldsymbol{\theta})=\mathbb{E}_{\mathbf{x}, y \sim \hat{p}_{\mathrm{data}}} \nabla_{\boldsymbol{\theta}} \log p_{\mathrm{model}}(\boldsymbol{x}, y ; \boldsymbol{\theta})
$$
실제로 데이터셋에서 작은 수의 예제를 랜덤하게 샘플링하고 그 예제에 대한 평균을 구해 이러한 기대치를 계산할 수 있다. 대부분의 최적화 알고리즘은 정확한 기울기를 천천히 계산하는 것보다 기울기의 근사된 추정치를 빠르게 계산할 수 있는 경우가 총 계산 관점에서 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;훨씬 더 빨리 수렴(converge)&lt;/b&gt;한다. 작은 샘플에서 기울기의 통계적인 추청에 동기를 부여하는 또 다른 고려사항은 트레이닝셋의 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;불필요한 중복(redundancy)&lt;/b&gt;이다. 기울기에 매우 유사한 기여를 하는 많은 예시를 찾을 수 있을 것이다. 
&lt;br /&gt;&lt;br /&gt;
전체 트레이닝셋을 사용하는 최적화 알고리즘을 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;batch &lt;/b&gt;또는 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;deterministic gradient method&lt;/b&gt;라 부른다. 한번에 하나의 예시만 사용하는 최적화 알고리즘은 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;stochastic&lt;/b&gt; 또는 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;online methods&lt;/b&gt;라 부른다. online이라는 용어는 주로 연속적으로 생성된 예제에서 추출할 때 사용된다. 딥러닝에 사용되는 알고리즘은 이 사이 어딘가 있지만, 모든 트레이닝 예제보다는 적게 사용한다. 이를 전통적으로 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;minibatch&lt;/b&gt; 또는 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;minibatch stochastic methods&lt;/b&gt;라 부른다. 이제는 simply stochastic methods로 흔히 부른다. 
&lt;br /&gt;&lt;br /&gt;
미니배치 크기는 일반적으로 다음과 같은 요인에 의해 나타난다.
&lt;ul&gt;
&lt;li&gt;배치 크기가 클수록 기울기에 대한 정확한 추정치를 제공하지만 linear returns 보단 아니다.&lt;/li&gt;
&lt;li&gt;Multicore architectures는 극도로 작은 배치에 의해 주로 이용되지 않는다. &lt;/li&gt;
&lt;li&gt;만약 배치의 모든 예시를 동시에(in parallel) 처리하려면 배치 사이즈에 따라 메모리 양을 조정해야한다.&lt;/li&gt;
&lt;li&gt;어떤 하드웨어는 특정한 크기의 array로 더 나은 실행시간(runtime)을 얻는다.&lt;/li&gt;
&lt;li&gt;작은 배치는 정규화 효과를 제공할 수 있다.&lt;/li&gt;
&lt;/ul&gt;
기울기 $\boldsymbol{g}$에만 기초하여 업데이트를 계산하는 방법은 주로 상대적으로 robust하고 100과 같이 더 작은 배치 크기를 처리할 수 있다. 또한, 헤시안 행렬 $\boldsymbol{H}$와 $\boldsymbol{H}^{-1}\boldsymbol{g}$와 같은 계산 업데이트를 사용하는 second-order methods는 일반적으로 10,000과 같은 훨씬 큰 배치 사이즈가 요구된다. 
&lt;br /&gt;&lt;br /&gt;
샘플 집합에서 기대되는 기울기의 unbiased estimate를 계산하려면 샘플이 독립이어야 한다. 또한, 두 개의 subsequent 미니배치 예제도 서로 독립이어야 한다. 많은 데이터셋은 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;연속적인(successive) 예시들이 높은 상관관계를 갖는 방식&lt;/b&gt;으로 가장 자연스럽게 배열된다. 이러한 경우, 데이터셋의 순서가 어느 정도 유의하면 미니배치를 선택하기 전에 예시를 섞을 필요가 있다. 
&lt;br /&gt;&lt;br /&gt;
minibatch stochastic gradient descent의 흥미로운 동기는 어떤 예제가 반복되지 않는 한 true 일반화 에러의 기울기를 따른다는 것이다. stochastic gradient descent가 일반화 오류를 최소화하는 사실은 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;online learning&lt;/b&gt;에서 가장 쉽게 볼 수 있으며 예시나 미니배치는 데이터 흐름으로 부터 나온다. 이 시나리오에서 예시는 절대 반복되지 않는다. 모든 experience는 $p_{\text{data}}$의 공정한 샘플이다.
&lt;br /&gt;&lt;br /&gt;
&lt;/div&gt;
</description>
        <pubDate>Sun, 12 Apr 2020 18:00:08 +0000</pubDate>
        <link>http://munjeongkang.github.io/ANN06/</link>
        <guid isPermaLink="true">http://munjeongkang.github.io/ANN06/</guid>
        
        
        <category>수업</category>
        
      </item>
    
      <item>
        <title>인공신경망 - Dropout</title>
        <description>&lt;hr /&gt;

&lt;div style=&quot;font-weight:500; font-size:1.0em; margin-left: 1em; margin-right: 1em;text-align:justify; &quot;&gt;
&lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;Dropout&lt;/b&gt;은 광범위한 모델 family를 정규화하는 계산적으로 효율적이고 강력한 방법을 제공한다. 드랍아웃은 매우 큰 신경망의 앙상블(ensembles)에 실용적인 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;bagging&lt;/b&gt;을 만드는 방법이라고 생각할 수 있다. Bagging은 다수의 모델을 훈련시키고 각 테스트 예제에서 다양한 모델을 평가하는 것을 포함한다. 그러나 각 모델이 큰 신경망일 때, 네트워크를 훈련하고 평가하는 것은 실행시간과 메모리 관점에서 비용이 많이 들기 때문에 비현실적으로 보인다. 그래서 5개~10개 사이의 신경망의 앙상블을 사용하는 것이 일반적이다. 드랍아웃은 기하급수적으로 많은 신경망의 bagged 앙상블을 훈련하고 평가하는데 inexpensive한 근사를 제공한다. 
&lt;br /&gt;&lt;br /&gt;
드랍아웃은 기본 네트워크에서 출력되지 않는 단위를 제거함으로써 만들 수 있는 모든 하위네트워크(subnetworks)로 구성된 앙상블을 훈련시킨다. 그 출력값에 0을 곱하면 네트워크에서 한 단위를 효과적으로 제거할 수 있다. 드랍아웃으로 트레이닝하기 위해 stochastic gradient descent와 같은 작은 스텍을 만드는 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;minibatch 기반 학습알고리즘&lt;/b&gt;을 사용한다. minibatch에 example을 load할 때마다, 네트워크의 모든 입력 단위와 숨겨진(hidden) 단위에 적용하기 위해 다른 binary mask를 무작위로 샘플링한다. 1의 mask 값을 샘플링할 확률은 훈련을 시작하기 전에 고정된 하이퍼 파라미터이다. 일반적으로 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;입력 단위는 0.8&lt;/b&gt;의 확률을 사용하고 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;숨겨진 단위는 0.5&lt;/b&gt;의 확률을 사용한다. 
&lt;br /&gt;&lt;br /&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/post_img/AN8.png&quot; width=&quot;450&quot; height=&quot;350&quot; /&gt;
&lt;/p&gt;

드랍아웃 트레이닝은 bagging 트레이닝과 같진 않다. 드랍아웃의 경우 모델은 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;파라미터를 공유&lt;/b&gt;하고 각 모델은 상위(parent) 신경망으로부터 다른 파라미터의 subset을 상속받는다. 이 파라미터 공유는 추적 가능한 메모리 양을 가진  기하급수적인 수의 모델을 나타낼 수 있게 해준다. 일반적으로 대부분의 모델은 명백하게(explicitly) 훈련되지 않는다. 대신, 가능한 하위 네트워크의 작은 부분이 single step에 각각 훈련되고, 파라미터 공유는 하위 네트워크가 좋은 파라미터 셋팅을 갖도록 한다. 

&lt;br /&gt;&lt;br /&gt;
&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/post_img/AN9.png&quot; width=&quot;450&quot; height=&quot;300&quot; /&gt;
&lt;/p&gt;

이제 모델의 역할이 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;확률분포를 출력하는 것&lt;/b&gt;이라고 가정해보자. mask 벡터 $\mu$에 의해 정의되는 각 하위 모델은 확률 분포 $p(y|x,\mu)$를 정의한다. 모든 mask에 대한 산술(arithmetic) 평균은 다음과 같이 주어진다. 
$$
\sum_{\boldsymbol{\mu}} p(\boldsymbol{\mu}) p(y | \boldsymbol{x}, \boldsymbol{\mu})
$$
여기서 $p(\mu)$는 트레이닝에서 $\mu$를 샘플링하는데 사용된 확률 분포다. 이 합은 지수적인 수의 항을 포함하기 때문에 모델의 구조가 단순화를 허용하는 경우를 제외하고 평가하기 어렵다. 지금까지 깊은(deep) 신경망은 어떤 다루기 쉬운 단순화도 허용하지 않는 것으로 알려져 있다. 대신 많은 masks로 부터 나온 아웃풋을 평균화함으로써 샘플링에 근사한 추론(inference)을 할 수 있다. 심지어 10~20개의 masks도 좋은 성능을 얻기에 충분하다. 
&lt;br /&gt;&lt;br /&gt;

&lt;span style=&quot;font-weight:700; font-size:1.3em;  margin-right: 1em;&quot;&gt;
Weight Scaling Inference Rule
&lt;/span&gt;
&lt;br /&gt;&lt;br /&gt;
그러나 훨씬 더 좋은 접근법은 단 하나의 forward 전파(propagation) cost로 전체 앙상블의 예측에 대한 좋은 근사치를 얻을 수 있게 해주는 것이다. 그렇게 하기 위해, 앙상블 멤버의 예측 분포의 산술 평균보다는 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;기하(geometric) 평균&lt;/b&gt;을 사용한다. Warde-Farley et al.(2014) 에서는 기하 평균이 산술 평균과 동등하게 수행된다는 주장과 경험적(empirical) 증거를 제시한다. 정규화되지 않은 확률 분포는 기하평균에 의해 다음과 같이 직접 정의된다. 

$$
\tilde{p}_{\text {ensemble }}(y | \boldsymbol{x})=\sqrt[2^{d}]{\prod_{\mu} p(y | \boldsymbol{x}, \boldsymbol{\mu})}
$$
여기서 $d$는 dropped 될 수 있는 단위의 수이다. 여기서는 표현을 단순히하기 위해 $\mu$에 대한 균등(uniform) 분포를 사용하지만 불균등(nonuniform) 분포 또한 가능하다. 예측을 하기 위해서는 앙상블을 다음과 같이 renormalize 해야한다. 
$$
p_{\text {ensemble }}(y | \boldsymbol{x})=\frac{\tilde{p}_{\text {ensemble }}(y | \boldsymbol{x})}{\sum_{y^{\prime}} \tilde{p}_{\text {ensemble }}\left(y^{\prime} | \boldsymbol{x}\right)}
$$

$p(y|x)$를 하나의 모델에서 평가함으로써 $p_{\text{ensemble}}$의 근사치를 구할 수 있다. 그 모델은 모든 단위를 포함하지만 단위 $i$를 벗어나는 가중치에 단위 $i$를 포함하는 확률을 곱한 것이다. 이러한 접근법을 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;weight scaling inference rule&lt;/b&gt; 이라 부른다. 깊은 비선형 네트워크에서 이 근사 추론 규칙의 정확성에 대해 아직 이론적인 argument는 없지만 경험적으로 매우 잘 작동된다.  
&lt;br /&gt;&lt;br /&gt;
비선형의 hidden units가 없는 모델의 많은 클래스의 경우 weight scaling inference rule이 정확하다. 간단한 예제로, 벡터 $v$로 표현되는 n개의 입력 변수를 가지는 소프트맥스 회귀 분류기는 다음과 같다. 
$$
P(\mathrm{y}=y | \mathbf{v})=\operatorname{softmax}\left(\boldsymbol{W}^{\top} \mathbf{v}+\boldsymbol{b}\right)_{y}
$$
이항 벡터 $d$를 가지는 인풋의 요소별(element-wise) 곱셈에 의해 하위 모델의 family를 다음과 같이 인덱싱할 수 있다. 
$$
\begin{align}
P(\mathrm{y}=y | \mathrm{v} ; d)=\operatorname{softmax}\left(W^{\top}(d \odot \mathrm{v})+b\right)_{y} \notag\\
P_{\text {ensemble }}(\mathrm{y}=y | \mathbf{v})=\frac{\tilde{P}_{\text {ensemble }}(\mathrm{y}=y | \mathbf{v})}{\sum_{y^{\prime}} \tilde{P}_{\text {ensemble }}\left(\mathrm{y}=y^{\prime} | \mathbf{v}\right)} \notag\\ 
\tilde{P}_{\text {ensemble }}(\mathrm{y}=y | \mathbf{v})= \sqrt[2^{n}]{\prod_{d \in\{0,1\}^{n}} P(\mathrm{y}=y | \mathbf{v} ; \mathbf{d})} \notag

\end{align}
$$

$$
\begin{align}

&amp;amp;=\sqrt[2^{n}]{\prod_{d \in\{0,1\}^{n}} \operatorname{softmax}\left(\boldsymbol{W}^{\top}(\boldsymbol{d} \odot \mathbf{v})+\boldsymbol{b}\right)_{y}} \notag\\ 
&amp;amp;=\sqrt[2^{n}]{\prod_{d \in\{0,1\}^{n}} \frac{\exp \left(\boldsymbol{W}_{y,:}^{\top}(\boldsymbol{d} \odot \mathbf{v})+b_{y}\right)}{\sum_{y^{\prime}} \exp \left(\boldsymbol{W}_{y^{\prime}, :}^{\top}(\boldsymbol{d} \odot \mathbf{v})+b_{y^{\prime}}\right)}} \notag\\ 
&amp;amp;=\frac{\sqrt[2^{n}]{\prod_{d \in\{0,1\}^{n}} \exp \left(\boldsymbol{W}_{y,:}^{\top}(\boldsymbol{d} \odot \mathbf{v})+b_{y}\right)}}{\sqrt[2^{n}]{\prod_{d \in\{0,1\}^{n}} \sum_{y^{\prime}} \exp \left(\boldsymbol{W}_{y^{\prime},:}^{\top}(\boldsymbol{d} \odot \mathbf{v})+b_{y^{\prime}}\right)}}\notag \\
\end{align} 
$$

$$
\begin{aligned} 
\tilde{P}_{\text {ensemble }}(\mathrm{y}=y |&amp;amp;\mathbf{v}) \propto \sqrt[2^{n}]{\prod_{d \in\{0,1\}^{n}} \exp \left(W_{y, i}^{\top}(d \odot \mathrm{v})+b_{y}\right)} 
\end{aligned}
$$

$$
\begin{array}{c}=\exp \left(\frac{1}{2^{n}} \sum_{\boldsymbol{d} \in\{0,1\}^{n}} \boldsymbol{W}_{y,:}^{\top}(\boldsymbol{d} \odot \mathbf{v})+b_{y}\right) \\ =\exp \left(\frac{1}{2} \boldsymbol{W}_{y,:}^{\top} \mathbf{v}+b_{y}\right)\end{array}
$$
weight scaling rule은 비선형성이 있는 deep 모델에 대한 근사치일 뿐이다. 비록 근사치가 이론적으로 특징되어지지 않지만, 경험적으로 잘 작동하는 경우가 많다.
&lt;br /&gt;&lt;br /&gt;

&lt;span style=&quot;font-weight:700; font-size:1.3em;  margin-right: 1em;&quot;&gt;
Advantages of Dropout
&lt;/span&gt;
&lt;br /&gt;&lt;br /&gt;

Srivastava et al. (2014)에서는 weight decay, filter norm constraints, sparse activity regularization과 같은 계산적으로 inexpensive한 표준 정규화 방법보다 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;dropout이 더 효과적&lt;/b&gt;이라는 것을 보였다. 드랍아웃의 장점은 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;계산적으로 매우 cheap&lt;/b&gt;하다는 것이다. 트레이닝을 할 때 드랍아웃을 사용하는 것은 example 업데이트당 O(n)계산만 하면 된다. 또한 역전파(back propagation) 단계까지 이진수를 저장하기 위해 O(n) 메모리가 요구된다. 또 다른 중요한 장점은 사용할 수 있는 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;모델이나 트레이닝 절차의 타입을 제한하지 않는다는 것&lt;/b&gt;이다. 분포로 표현한 거의 모든 모델에서 잘 작동하고 stochastic gradient descent로 트레이닝 될 수 있다. 

&lt;br /&gt;&lt;br /&gt;

dropout의 상당 부분은 hidden units에 masking noise가 적용된다는 사실에서 발생한다는 점을 이해하는 것이 중요하다. 이것은 입력값의 raw values 보다 information content에 대한 고도의 지능적이고 적응적인 destruction 형태로 볼 수 있다. 원래 값보다 추출된 특징을 파괴하면 destruction 프로세스가 지금까지 획득한 입력 분포에 대한 모든 지식을 사용할 수 있다. 
&lt;/div&gt;
</description>
        <pubDate>Sat, 11 Apr 2020 18:00:08 +0000</pubDate>
        <link>http://munjeongkang.github.io/ANN5/</link>
        <guid isPermaLink="true">http://munjeongkang.github.io/ANN5/</guid>
        
        
        <category>수업</category>
        
      </item>
    
      <item>
        <title>인공신경망 - Parameter Norm Penalties</title>
        <description>&lt;hr /&gt;

&lt;div style=&quot;font-weight:500; font-size:1.0em; margin-left: 1em; margin-right: 1em;text-align:justify; &quot;&gt;
&lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;정규화&lt;/b&gt;는 딥러닝의 출현 이전에도 수십년 동안 사용되어 왔다. 선형 회귀모형이나 로지스틱 회귀모형 같은 선형 모델은 간단하고 효과적인 정규화가 가능하다. 많은 정규화 방법은 목적함수 $J$에 파라미터 norm penalty $\Omega(\theta)$를 추가하여 모델의 capacity를 제한하는 것에 기초한다. 정규화된 목적함수는 다음과 같다. 
&lt;p align=&quot;center&quot;&gt;
$$
\tilde{J}(\boldsymbol{\theta} ; \boldsymbol{X}, \boldsymbol{y})=J(\boldsymbol{\theta} ; \boldsymbol{X}, \boldsymbol{y})+\alpha \Omega(\boldsymbol{\theta}), \quad \text { where } \alpha \in[0, \infty)
$$
&lt;/p&gt;
$\alpha$를 0으로 설정하면 정규화가 되지 않고 $\alpha$의 값이 클수록 더 정규화된다. &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;parameter norm&lt;/b&gt; $\Omega$에 대해 다른 솔루션이 더 선호될 수 있다. 일반적으로 각 계층에서 affine 변환의 가중치에 대해서만 패널티를 주고 편차(bias)를 정규화하지 않는 파라미터 norm penalty $\Omega$를 사용한다. 편차를 정확하게 fit하기 위해 가중치보다 더 적은 데이터가 필요하고 편차 파라미터 정규화는 상당한 underfitting 양을 도입할 수 있다. 
&lt;br /&gt;&lt;br /&gt;
&lt;span style=&quot;font-weight:700; font-size:1.3em;  margin-right: 1em;&quot;&gt;
$L^2$ Parameter Regularization
&lt;/span&gt;
&lt;br /&gt;&lt;br /&gt;
$L^2$ parameter norm penalty는 흔히 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;weight decay&lt;/b&gt;로 알려져 있다. 
$$
\begin{array}{c}\Omega(\boldsymbol{\theta})=\frac{1}{2}\|\boldsymbol{w}\|_{2}^{2} \\ \tilde{J}(\boldsymbol{w} ; \boldsymbol{X}, \boldsymbol{y})=\frac{\alpha}{2} \boldsymbol{w}^{\top} \boldsymbol{w}+J(\boldsymbol{w} ; \boldsymbol{X}, \boldsymbol{y}) \\ \nabla_{\boldsymbol{w}} \tilde{J}(\boldsymbol{w} ; \boldsymbol{X}, \boldsymbol{y})=\alpha \boldsymbol{w}+\nabla_{\boldsymbol{w}} J(\boldsymbol{w} ; \boldsymbol{X}, \boldsymbol{y})\end{array}
$$
single gradient step을 수행하여 가중치를 업데이트 하는 방법은 다음과 같다. 
$$

\begin{array}{l}\boldsymbol{w} \leftarrow \boldsymbol{w}-\epsilon\left(\alpha \boldsymbol{w}+\nabla_{\boldsymbol{w}} J(\boldsymbol{w} ; \boldsymbol{X}, \boldsymbol{y})\right) \\ \boldsymbol{w} \leftarrow(1-\epsilon \alpha) \boldsymbol{w}-\epsilon \nabla_{\boldsymbol{w}} J(\boldsymbol{w} ; \boldsymbol{X}, \boldsymbol{y})\end{array}
$$

정규화되지 않은 트레이닝 비용을 최소화하는 가중치 값과 인접한 목적 함수에 대한 2차(quadratic) 근사를 만들어 분석을 단순하게 할 수 있다. 여기서 $H$는 $w^*$에서 평가된 $w$에 관한 $J$의 헤시안(Hessian) 행렬이다. 
$$
\begin{aligned} 
&amp;amp;\boldsymbol{w}^{*}=\arg \min _{\boldsymbol{w}} J(\boldsymbol{w}) \\
&amp;amp;\hat{J}(\boldsymbol{\theta}) =J\left(\boldsymbol{w}^{*}\right)+\frac{1}{2}\left(\boldsymbol{w}-\boldsymbol{w}^{*}\right)^{\top} \boldsymbol{H}\left(\boldsymbol{w}-\boldsymbol{w}^{*}\right) 
\end{aligned}
$$
gradient가 0일 때 $\hat{J}$가 최소가 된다. 
$$
\nabla_{\boldsymbol{w}} \hat{J}(\boldsymbol{w})=\boldsymbol{H}\left(\boldsymbol{w}-\boldsymbol{w}^{*}\right)
$$
이제 정규화된 $\hat{J}$의 최소값을 다음과 같이 구할 수 있게 된다. 
$$
\begin{array}{c}\alpha \tilde{\boldsymbol{w}}+\boldsymbol{H}\left(\tilde{\boldsymbol{w}}-\boldsymbol{w}^{*}\right)=0 \\ (\boldsymbol{H}+\alpha \boldsymbol{I}) \tilde{\boldsymbol{w}}=\boldsymbol{H} \boldsymbol{w}^{*} \\ \tilde{\boldsymbol{w}}=(\boldsymbol{H}+\alpha \boldsymbol{I})^{-1} \boldsymbol{H} \boldsymbol{w}^{*}\end{array}
$$
$\boldsymbol{H}=Q \Lambda Q^{\top}$로 분해(decompose) 할 수 있다. 
$$
\begin{aligned} \tilde{w} &amp;amp;=\left(Q \Lambda Q^{\top}+\alpha I\right)^{-1} Q \Lambda Q^{\top} w^{*} \\ &amp;amp;=\left[Q(\Lambda+\alpha I) Q^{\top}\right]^{-1} Q \Lambda Q^{\top} w^{*} \\ &amp;amp;=Q(\Lambda+\alpha I)^{-1} \Lambda Q^{\top} w^{*} \end{aligned}
$$
weight decay의 효과는 $\boldsymbol{H}$의 고유벡터(eigenvector)로 정의된 축을 따라서 $w^{*}$를 rescale하는 것이다. $\boldsymbol{H}$의 i번째 고유벡터로 정렬된 $w^*$의 성분은 $\lambda_i / (\lambda_i+\alpha)$ 의 인수로 재조정된다. $\boldsymbol{H}$의 고유값(eigenvalue)이 상대적으로 큰 방향을 따르면 (ex. $\lambda_i &amp;gt;&amp;gt; \alpha$) 정규화의 효과는 상대적으로 작아진다. 그러나 $\lambda_i &amp;lt;&amp;lt; \alpha$인 성분의 크기는 거의 0에 가까울 정도로 줄어들 것이다. 
&lt;br /&gt;&lt;br /&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/post_img/AN7.png&quot; width=&quot;400&quot; height=&quot;300&quot; /&gt;
&lt;/p&gt;

&lt;span style=&quot;font-weight:700; font-size:1.3em;  margin-right: 1em;&quot;&gt;
$L^1$ Regularization
&lt;/span&gt;
&lt;br /&gt;&lt;br /&gt;
$L^2$ weight decay가 weight decay의 가장 흔한 형식인 반면에, 모델 파라미터의 사이즈를 패널라이즈(penalize)하는 다른 방법도 있다. 그것은 바로 다음과 같이 $L^1$ 정규화를 사용하는 것이다. 
$$
\begin{array}{c}\Omega(\boldsymbol{\theta})=\|\boldsymbol{w}\|_{1}=\sum\left|w_{i}\right| \\ \tilde{J}(\boldsymbol{w} ; \boldsymbol{X}, \boldsymbol{y})=\alpha\|\boldsymbol{w}\|_{1}+J(\boldsymbol{w} ; \boldsymbol{X}, \boldsymbol{y}) \\ \nabla_{w} \tilde{J}(\boldsymbol{w} ; \boldsymbol{X}, \boldsymbol{y})=\alpha \operatorname{sign}(\boldsymbol{w})+\nabla_{w} J(\boldsymbol{X}, y ; \boldsymbol{w})\end{array}
$$
$H=\operatorname{diag}\left(\left[H_{1,1}, \ldots, H_{n, n}\right]\right)$와 같이 헤시안이 대각(diagonal)이라는 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;더욱 간단한 가정&lt;/b&gt;을 한다. 이 가정은 입력 특징들 사이의 모든 상관관계(correlation)를 제거하기 위해 선형회귀 문제에 대한 데이터가 전처리된 경우에 적용된다.
&lt;br /&gt;&lt;br /&gt;
$L^1$ 정규화된 목적 함수의 2차 근사는 다음과 같이 파라미터에 걸쳐 합(sum)으로 분해된다. 
$$
\hat{J}(\boldsymbol{w} ; \boldsymbol{X}, \boldsymbol{y})=J\left(\boldsymbol{w}^{*} ; \boldsymbol{X}, \boldsymbol{y}\right)+\sum_{i}\left[\frac{1}{2} H_{i, i}\left(\boldsymbol{w}_{i}-\boldsymbol{w}_{i}^{*}\right)^{2}+\alpha\left|w_{i}\right|\right]
$$
비용함수의 근사를 최소화하는 문제는 다음과 같은 형태로 각 차원 $i$에 대한 분석적인 솔루션을 가진다. 
$$
w_{i}=\operatorname{sign}\left(w_{i}^{*}\right) \max \left\{\left|w_{i}^{*}\right|-\frac{\alpha}{H_{i, i}}, 0\right\}
$$

모든 $i$에 대해 $w^*_i &amp;gt; 0$인 상황을 고려해보자.

&lt;ol&gt;
&lt;li&gt;$w^*_i \le \alpha / H_{i,i}$인 경우 &lt;br /&gt;
여기서 $w_i = 0$ 이다. 정규화된 목적합수에 대한 $J(w;X,y)$의 contribution이 $L^1$ 정규화에 의해 $i$ 방향으로 overwhelmed 되기 때문에 발생한다.  &lt;/li&gt;
&lt;li&gt;$w^*_i &amp;gt; \alpha / H_{i,i}$인 경우 &lt;br /&gt;
이 경우는 정규화가 $w_i$의 최적값을 0으로 이동시키는 것이 아니라 $\alpha H_{i,i}$와 같은 거리만큼 그 방향으로만 이동시킨다.&lt;/li&gt;
&lt;/ol&gt;

$L^2$ 정규화와 비교하여 $L^1$ 정규화는 더 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;희소한(sparse)&lt;/b&gt;한 솔루션을 준다. $L^1$ 정규화에 의해 유도된 희소성질 (sparsity property)은 특징 선택 (feature selection) 매커니즘으로 광범위하게 사용되어왔다. 
&lt;/div&gt;
</description>
        <pubDate>Sat, 11 Apr 2020 18:00:08 +0000</pubDate>
        <link>http://munjeongkang.github.io/ANN4/</link>
        <guid isPermaLink="true">http://munjeongkang.github.io/ANN4/</guid>
        
        
        <category>수업</category>
        
      </item>
    
      <item>
        <title>인공신경망 - Output Units</title>
        <description>&lt;hr /&gt;

&lt;div style=&quot;font-weight:500; font-size:1.0em; margin-left: 1em; margin-right: 1em;text-align:justify; &quot;&gt;
비용 함수의 선택은 출력 단위(output unit)의 선택과 밀접하게 연결된다. 대부분의 경우, 단순하게 데이터 분포와 모델 분포 사이의 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;cross-entropy&lt;/b&gt;를 사용한다. 우리는 feedforward 네트워크가 $h=f(x;\theta)$로 정의된 숨겨진 특징(hidden features)을 제공한다고 가정한다. 출력 계층(output layer)의 역할은 네트워크가 수행해야 하는 task를 완료하기 위하여 특징에 추가적인 변환을 제공하는 것이다.
&lt;br /&gt;&lt;br /&gt;
&lt;span style=&quot;font-weight:700; font-size:1.3em;  margin-right: 1em;&quot;&gt;
Linear Units for Gaussian Output Distributions
&lt;/span&gt;
&lt;br /&gt;&lt;br /&gt;
간단한 출력 단위 중 하나는 비선형성(nonlinearity)이 없는 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;affine 변환&lt;/b&gt;에 기초한 것이다. 이것들은 주로 선형 단위로 불리며 특징 $h$가 주어질 때, 선형 출력 단위의 계층은 벡터 $\hat{y}=W^{\top} h+b$를 생성한다. 선형 출력 계층들은 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;조건부 가우시안 분포&lt;/b&gt;인 $p(\boldsymbol{y} | \boldsymbol{x})=\mathcal{N}(\boldsymbol{y} ; \hat{\boldsymbol{y}}, \boldsymbol{I})$의 평균을 생성하는데 사용된다. 선형 단위는 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;포화 상태(saturate)가 아니기&lt;/b&gt; 때문에 기울기(gradient) 기반 최적화 알고리즘에는 별다른 어려움이 없으며 다양한 최적화 알고리즘과 함께 사용될 수 있다. 
&lt;br /&gt;&lt;br /&gt;

&lt;span style=&quot;font-weight:700; font-size:1.3em;  margin-right: 1em;&quot;&gt;
Sigmoid Units for Bernoulli Output Distributions
&lt;/span&gt;
&lt;br /&gt;&lt;br /&gt;
많은 작업에서 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;이진 변수&lt;/b&gt;(binary variable)인 $y$값을 예측해야 한다. 베르누이 분포는 단 하나의 수로 정의되므로 신경망(neural net)은 $P(y=1|x)$만 예측하면 된다. 이 숫자가 유효한 확률이 되려면 [0,1]간격에 있어야 하고 이 제약을 만족하려면 신중하게 디자인 할 필요가 있다. 유효한 확률을 얻기 위해 선형 단위를 사용하고 그 값을 한계점(threshold)으로 사용한다고 다음과 같이 가정한다.&lt;br /&gt;
&lt;p align=&quot;center&quot;&gt;
&lt;br /&gt;
 $P(y=1 | \boldsymbol{x})=\max \left\{0, \min \left\{1, \boldsymbol{w}^{\top} \boldsymbol{h}+b\right\}\right\}$
 &lt;/p&gt;
경사하강법(gradient decent)으로는 이를 매우 효과적으로 훈련시킬 수 없다. $w^{\top} h+b$가 단위 구간을 벗어나면 파라미터에 대한 모델의 아웃풋 기울기가 0이 되기 때문이다. 대신 모델이 잘못된 답을 줄 때마다 항상 강한(strong) 기울기를 보장하는 다른 접근법을 사용하는 것이 좋다. &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;시그모이드 출력 단위&lt;/b&gt;는 $\hat{y}=\sigma\left(\boldsymbol{w}^{\top} \boldsymbol{h}+b\right)$로 정의되며 $\sigma$는 로지스틱 시그모이드 함수이다. 
&lt;br /&gt;&lt;br /&gt;
시그모이드 출력 단위는 두 개의 구성 요소를 가지고 있다고 생각할 수 있다. 
&lt;ol&gt;
&lt;li&gt;$z=w^{\top} h+b$를 계산하기 위해 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;선형 레이어&lt;/b&gt;를 사용하는 것&lt;/li&gt;
&lt;li&gt;$z$를 확률로 변환하기 위해 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;시그모이드 활성화(activation) 함수&lt;/b&gt;를 사용하는 것&lt;/li&gt;
&lt;/ol&gt;
만약 비정규화된(unnormalized) 로그 확률이 $y$와 $z$에서 선형이라고 가정한다면 비정규화된 확률을 얻기 위해 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;지수화(exponentiate)&lt;/b&gt;할 수 있다. $z$의 시그모이드 변환에 의해 베르누이 분포 산출을 위한 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;정규화&lt;/b&gt; 과정은 다음과 같다. 
&lt;br /&gt;&lt;br /&gt;
&lt;p align=&quot;center&quot;&gt;
$\begin{aligned} 
\log \tilde{P}(y) &amp;amp;=y z \\ 
\tilde{P}(y) &amp;amp;=\exp (y z) \\ 
P(y) &amp;amp;=\frac{\exp (y z)}{\sum_{y^{\prime}=0}^{1} \exp \left(y^{\prime} z\right)} \\ 
P(y) &amp;amp;=\sigma((2 y-1) z) 
\end{aligned}$
&lt;/p&gt;
로그 공간에서 확률을 예측하는 이 접근법은 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;최대 우도(maximum likelihood)&lt;/b&gt; 학습에 사용하는 것이 보통이다. 왜냐하면 최대 우도에 사용되는 비용 함수가 $ \log P(y|x)$이기 때문에, 비용함수에서 로그는 시그모이드의 exp를 없애준다. 이러한 효과가 없다면, 시그모이드의 포화상태는 gradient 기반 학습의 진전을 막았을 것이다. 
&lt;br /&gt;&lt;br /&gt;
시그모이드에 의해 파라미터화되는 베르누이의 최대 우도 학습에 대한 손실 함수(loss function)는 다음과 같다. $\zeta$ 는 softplus 함수이다.
&lt;br /&gt;&lt;br /&gt;
&lt;p align=&quot;center&quot;&gt;
$ \begin{aligned} 
J(\boldsymbol{\theta}) &amp;amp;=-\log P(y | \boldsymbol{x}) \\ 
&amp;amp;=-\log \sigma((2 y-1) z) \\ 
&amp;amp;=\zeta((1-2 y) z) 
\end{aligned}$
&lt;/p&gt;
$(1-2y)z$가 very negative(매우 작은 음수)한 경우만 포화되므로 포화상태는 모델이 이미 올바른 정답을 가지고 있을 때만 발생한다. 즉, $y=1$ 이고 $z$가 very positive(매우 큰 양수) 하거나 $y=0$이고 $z$가 very negative 한 경우만 발생한다. $z$가 잘못된 사인을 가질 때, softplus 함수에 대한 인수(argument) $(1-2y)z$는 $|z|$로 단순화될 수 있다. 
&lt;br /&gt;&lt;br /&gt;
&lt;span style=&quot;font-weight:700; font-size:1.3em;  margin-right: 1em;&quot;&gt;
Softmax Units for Multinoulli Output Distributions
&lt;/span&gt;
&lt;br /&gt;&lt;br /&gt;
$n$개의 값을 가지는 이산 변수의 경우로 일반화하기 위해 $\hat{y}_{i}=P(y=i | \boldsymbol{x})$에 대한 벡터 $\hat{y}$가 필요하다. 먼저 선형 계층이 비정규화된 로그 확률을 다음과 같이 예측한다.
 &lt;p align=&quot;center&quot;&gt;
&lt;br /&gt;
 $z=W^{\top}h+b \quad $ where $z_{i}=\log \tilde{P}(y=i | \boldsymbol{x})$
 &lt;/p&gt;
소프트맥스 함수는 원하는 $\hat{y}$를 얻기 위해 $z$를 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;지수화&lt;/b&gt;하고 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;정규화&lt;/b&gt;할 수 있다. 
&lt;p align=&quot;center&quot;&gt;
&lt;br /&gt;
 $\operatorname{softmax}(\boldsymbol{z})_{i}=\frac{\exp \left(z_{i}\right)}{\sum_{j} \exp \left(z_{j}\right)}$
 &lt;/p&gt;
이를 다음과 같이 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;최대화&lt;/b&gt; 하길 원한다. 
&lt;p align=&quot;center&quot;&gt;
&lt;br /&gt;
 $ \begin{aligned} 
 \log P(\mathrm{y}=i ; z)&amp;amp;=\log \operatorname{softmax}(z)_{i} \\
 \log \operatorname{softmax}(\boldsymbol{z})_{i}&amp;amp;=z_{i}-\log \sum_{j} \exp \left(z_{j}\right)
 \end{aligned}
 $
 &lt;/p&gt;
 두번째 항은 $\max_j z_j$로 근사될 수 있다. 만약 올바른 답이 소프트맥스에 대한 가장 큰 입력을 이미 가지고 있다면, $-z_i$ 항과 $\log \sum_{j} \exp \left(z_{j}\right) \approx \max _{j} z_{j}=z_{i}$ 항은 거의 취소된다. 이 예제는 전체 트레이닝 비용에는 기여하지 못하지만 아직 정확하게 분류되지 않은 다른 예제에 의해 지배될(dominated) 것이다. 
 &lt;br /&gt;&lt;br /&gt;

신경과학적인(neuroscientific) 관점에서 소프트 맥스를 단위들 사이의 경쟁의 형태로 만든다는 생각은 흥미롭다. 
&lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;소프트맥스 아웃풋의 합은 항상 1&lt;/b&gt;이기 때문에 한 단위 값이 증가하면 다른 단위 값은 감소한다. 이는 피질(cortex) 안에 있는 근처 뉴런사이에 존재하는 것으로 여겨지는 측면 억제(lateral inhibition)와 유사하다. &quot;소프트(soft)&quot;라는 용어는 소프트맥스가 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;연속&lt;/b&gt;이고 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;미분가능하다&lt;/b&gt;는 사실에서 유래하였으며, 소프트맥스 함수는 argmax의 softened 버전을 제공한다. 
&lt;br /&gt;&lt;br /&gt;

&lt;span style=&quot;font-weight:700; font-size:1.3em;  margin-right: 1em;&quot;&gt;
Other Output Types
&lt;/span&gt;
&lt;br /&gt;&lt;br /&gt;
신경망(neural network)은 우리가 원하는 거의 모든 종류의 출력계층을 일반화할 수 있다. &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;최대 우도 원리(principle)&lt;/b&gt;는 출력 계층에 대해 비용 함수를 좋게 설계하는 방법에 대한 가이드를 준다. 조건부 분포 $p(y|x;\theta)$를 정의한다면 최대우도원리는 비용 함수를 $\log p(y|x;\theta)$로 사용하도록 한다. 
&lt;br /&gt;&lt;br /&gt;
일반적으로 신경망은 함수 $f(x;\theta)$를 표현하는 것으로 생각할 수 있다. 이 함수의 아웃풋은 $y$ 값을 직접 예측하는 것은 아니다. 대신 $f(x;\theta)=\omega$가 $y$ 에 대한 분포의 파라미터를 제공한다. 손실함수는 $-\log p(y;\omega(x))$로 해석될 수 있다. 
&lt;br /&gt;&lt;br /&gt;
우리는 가끔 multimodal regression을 수행할 수도 있다. 이는 동일한 $x$값에 대해 y 스페이스에 여러개의 다른 peak들을 가질 수 있는 조건부 분포 $p(y|x)$에서 실제 값을 예측하는 것이다. 이 경우에는 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;Gaussian mixture&lt;/b&gt;를 아웃풋으로 하고 이런 신경망을 흔히 mixture density networks라고 한다. 
&lt;p align=&quot;center&quot;&gt;
$$
p(\boldsymbol{y} | \boldsymbol{x})=\sum_{i=1}^{n} p(\mathrm{c}=i | \boldsymbol{x}) \mathcal{N}\left(\boldsymbol{y} ; \boldsymbol{\mu}^{(i)}(\boldsymbol{x}), \boldsymbol{\Sigma}^{(i)}(\boldsymbol{x})\right)$$
&lt;/p&gt;
그러나 조건부 가우시안 혼합의 gradient 기반 최적화는 신뢰할 수 없다. 왜냐하면 수치적으로 불안정한 분산에 의한 division을 얻을 수 있기 때문이다. 특정한 예시에서 일부 분산이 작은 경우 매우 큰 gradient를 산출한다. 가우시안 혼합 아웃풋은 특히 물리적인 객체의 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;음성&lt;/b&gt;과 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;움직임&lt;/b&gt;의 생성 모델에 효과적이다. 아래 그림은 mixture density의 아웃풋이다. 
&lt;br /&gt;&lt;br /&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/post_img/AN6.png&quot; width=&quot;650&quot; height=&quot;300&quot; /&gt;
&lt;/p&gt;
&lt;/div&gt;
</description>
        <pubDate>Sat, 11 Apr 2020 18:00:08 +0000</pubDate>
        <link>http://munjeongkang.github.io/ANN3/</link>
        <guid isPermaLink="true">http://munjeongkang.github.io/ANN3/</guid>
        
        
        <category>수업</category>
        
      </item>
    
  </channel>
</rss>
