<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>코딩새내기 일상일지</title>
    <description>github blog</description>
    <link>http://munjeongkang.github.io/</link>
    <atom:link href="http://munjeongkang.github.io/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Sat, 11 Apr 2020 23:32:19 +0900</pubDate>
    <lastBuildDate>Sat, 11 Apr 2020 23:32:19 +0900</lastBuildDate>
    <generator>Jekyll v2.5.3</generator>
    
      <item>
        <title>인공신경망 - Dropout</title>
        <description>&lt;hr /&gt;

&lt;div style=&quot;font-weight:500; font-size:1.0em; margin-left: 1em; margin-right: 1em;text-align:justify; &quot;&gt;
&lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;Dropout&lt;/b&gt;은 광범위한 모델 family를 정규화하는 계산적으로 효율적이고 강력한 방법을 제공한다. 드랍아웃은 매우 큰 신경망의 앙상블(ensembles)에 실용적인 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;bagging&lt;/b&gt;을 만드는 방법이라고 생각할 수 있다. Bagging은 다수의 모델을 훈련시키고 각 테스트 예제에서 다양한 모델을 평가하는 것을 포함한다. 그러나 각 모델이 큰 신경망일 때, 네트워크를 훈련하고 평가하는 것은 실행시간과 메모리 관점에서 비용이 많이 들기 때문에 비현실적으로 보인다. 그래서 5개~10개 사이의 신경망의 앙상블을 사용하는 것이 일반적이다. 드랍아웃은 기하급수적으로 많은 신경망의 bagged 앙상블을 훈련하고 평가하는데 inexpensive한 근사를 제공한다. 
&lt;br /&gt;&lt;br /&gt;
드랍아웃은 기본 네트워크에서 출력되지 않는 단위를 제거함으로써 만들 수 있는 모든 하위네트워크(subnetworks)로 구성된 앙상블을 훈련시킨다. 그 출력값에 0을 곱하면 네트워크에서 한 단위를 효과적으로 제거할 수 있다. 드랍아웃으로 트레이닝하기 위해 stochastic gradient descent와 같은 작은 스텍을 만드는 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;minibatch 기반 학습알고리즘&lt;/b&gt;을 사용한다. minibatch에 example을 load할 때마다, 네트워크의 모든 입력 단위와 숨겨진(hidden) 단위에 적용하기 위해 다른 binary mask를 무작위로 샘플링한다. 1의 mask 값을 샘플링할 확률은 훈련을 시작하기 전에 고정된 하이퍼 파라미터이다. 일반적으로 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;입력 단위는 0.8&lt;/b&gt;의 확률을 사용하고 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;숨겨진 단위는 0.5&lt;/b&gt;의 확률을 사용한다. 
&lt;br /&gt;&lt;br /&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/post_img/AN8.png&quot; width=&quot;450&quot; height=&quot;350&quot; /&gt;
&lt;/p&gt;

드랍아웃 트레이닝은 bagging 트레이닝과 같진 않다. 드랍아웃의 경우 모델은 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;파라미터를 공유&lt;/b&gt;하고 각 모델은 상위(parent) 신경망으로부터 다른 파라미터의 subset을 상속받는다. 이 파라미터 공유는 추적 가능한 메모리 양을 가진  기하급수적인 수의 모델을 나타낼 수 있게 해준다. 일반적으로 대부분의 모델은 명백하게(explicitly) 훈련되지 않는다. 대신, 가능한 하위 네트워크의 작은 부분이 single step에 각각 훈련되고, 파라미터 공유는 하위 네트워크가 좋은 파라미터 셋팅을 갖도록 한다. 

&lt;br /&gt;&lt;br /&gt;
&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/post_img/AN9.png&quot; width=&quot;450&quot; height=&quot;300&quot; /&gt;
&lt;/p&gt;

이제 모델의 역할이 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;확률분포를 출력하는 것&lt;/b&gt;이라고 가정해보자. mask 벡터 $\mu$에 의해 정의되는 각 하위 모델은 확률 분포 $p(y|x,\mu)$를 정의한다. 모든 mask에 대한 산술(arithmetic) 평균은 다음과 같이 주어진다. 
$$
\sum_{\boldsymbol{\mu}} p(\boldsymbol{\mu}) p(y | \boldsymbol{x}, \boldsymbol{\mu})
$$
여기서 $p(\mu)$는 트레이닝에서 $\mu$를 샘플링하는데 사용된 확률 분포다. 이 합은 지수적인 수의 항을 포함하기 때문에 모델의 구조가 단순화를 허용하는 경우를 제외하고 평가하기 어렵다. 지금까지 깊은(deep) 신경망은 어떤 다루기 쉬운 단순화도 허용하지 않는 것으로 알려져 있다. 대신 많은 masks로 부터 나온 아웃풋을 평균화함으로써 샘플링에 근사한 추론(inference)을 할 수 있다. 심지어 10~20개의 masks도 좋은 성능을 얻기에 충분하다. 
&lt;br /&gt;&lt;br /&gt;

&lt;span style=&quot;font-weight:700; font-size:1.3em;  margin-right: 1em;&quot;&gt;
Weight Scaling Inference Rule
&lt;/span&gt;
&lt;br /&gt;&lt;br /&gt;
그러나 훨씬 더 좋은 접근법은 단 하나의 forward 전파(propagation) cost로 전체 앙상블의 예측에 대한 좋은 근사치를 얻을 수 있게 해주는 것이다. 그렇게 하기 위해, 앙상블 멤버의 예측 분포의 산술 평균보다는 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;기하(geometric) 평균&lt;/b&gt;을 사용한다. Warde-Farley et al.(2014) 에서는 기하 평균이 산술 평균과 동등하게 수행된다는 주장과 경험적(empirical) 증거를 제시한다. 정규화되지 않은 확률 분포는 기하평균에 의해 다음과 같이 직접 정의된다. 

$$
\tilde{p}_{\text {ensemble }}(y | \boldsymbol{x})=\sqrt[2^{d}]{\prod_{\mu} p(y | \boldsymbol{x}, \boldsymbol{\mu})}
$$
여기서 $d$는 dropped 될 수 있는 단위의 수이다. 여기서는 표현을 단순히하기 위해 $\mu$에 대한 균등(uniform) 분포를 사용하지만 불균등(nonuniform) 분포 또한 가능하다. 예측을 하기 위해서는 앙상블을 다음과 같이 renormalize 해야한다. 
$$
p_{\text {ensemble }}(y | \boldsymbol{x})=\frac{\tilde{p}_{\text {ensemble }}(y | \boldsymbol{x})}{\sum_{y^{\prime}} \tilde{p}_{\text {ensemble }}\left(y^{\prime} | \boldsymbol{x}\right)}
$$

$p(y|x)$를 하나의 모델에서 평가함으로써 $p_{\text{ensemble}}$의 근사치를 구할 수 있다. 그 모델은 모든 단위를 포함하지만 단위 $i$를 벗어나는 가중치에 단위 $i$를 포함하는 확률을 곱한 것이다. 이러한 접근법을 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;weight scaling inference rule&lt;/b&gt; 이라 부른다. 깊은 비선형 네트워크에서 이 근사 추론 규칙의 정확성에 대해 아직 이론적인 argument는 없지만 경험적으로 매우 잘 작동된다.  
&lt;br /&gt;&lt;br /&gt;
비선형의 hidden units가 없는 모델의 많은 클래스의 경우 weight scaling inference rule이 정확하다. 간단한 예제로, 벡터 $v$로 표현되는 n개의 입력 변수를 가지는 소프트맥스 회귀 분류기는 다음과 같다. 
$$
P(\mathrm{y}=y | \mathbf{v})=\operatorname{softmax}\left(\boldsymbol{W}^{\top} \mathbf{v}+\boldsymbol{b}\right)_{y}
$$
이항 벡터 $d$를 가지는 인풋의 요소별(element-wise) 곱셈에 의해 하위 모델의 family를 다음과 같이 인덱싱할 수 있다. 
$$
\begin{align}
P(\mathrm{y}=y | \mathrm{v} ; d)=\operatorname{softmax}\left(W^{\top}(d \odot \mathrm{v})+b\right)_{y} \notag\\
P_{\text {ensemble }}(\mathrm{y}=y | \mathbf{v})=\frac{\tilde{P}_{\text {ensemble }}(\mathrm{y}=y | \mathbf{v})}{\sum_{y^{\prime}} \tilde{P}_{\text {ensemble }}\left(\mathrm{y}=y^{\prime} | \mathbf{v}\right)} \notag\\ 
\tilde{P}_{\text {ensemble }}(\mathrm{y}=y | \mathbf{v})= \sqrt[2^{n}]{\prod_{d \in\{0,1\}^{n}} P(\mathrm{y}=y | \mathbf{v} ; \mathbf{d})} \notag

\end{align}
$$

$$
\begin{align}

&amp;amp;=\sqrt[2^{n}]{\prod_{d \in\{0,1\}^{n}} \operatorname{softmax}\left(\boldsymbol{W}^{\top}(\boldsymbol{d} \odot \mathbf{v})+\boldsymbol{b}\right)_{y}} \notag\\ 
&amp;amp;=\sqrt[2^{n}]{\prod_{d \in\{0,1\}^{n}} \frac{\exp \left(\boldsymbol{W}_{y,:}^{\top}(\boldsymbol{d} \odot \mathbf{v})+b_{y}\right)}{\sum_{y^{\prime}} \exp \left(\boldsymbol{W}_{y^{\prime}, :}^{\top}(\boldsymbol{d} \odot \mathbf{v})+b_{y^{\prime}}\right)}} \notag\\ 
&amp;amp;=\frac{\sqrt[2^{n}]{\prod_{d \in\{0,1\}^{n}} \exp \left(\boldsymbol{W}_{y,:}^{\top}(\boldsymbol{d} \odot \mathbf{v})+b_{y}\right)}}{\sqrt[2^{n}]{\prod_{d \in\{0,1\}^{n}} \sum_{y^{\prime}} \exp \left(\boldsymbol{W}_{y^{\prime},:}^{\top}(\boldsymbol{d} \odot \mathbf{v})+b_{y^{\prime}}\right)}}\notag \\
\end{align} 
$$

$$
\begin{aligned} 
\tilde{P}_{\text {ensemble }}(\mathrm{y}=y |&amp;amp;\mathbf{v}) \propto \sqrt[2^{n}]{\prod_{d \in\{0,1\}^{n}} \exp \left(W_{y, i}^{\top}(d \odot \mathrm{v})+b_{y}\right)} 
\end{aligned}
$$

$$
\begin{array}{c}=\exp \left(\frac{1}{2^{n}} \sum_{\boldsymbol{d} \in\{0,1\}^{n}} \boldsymbol{W}_{y,:}^{\top}(\boldsymbol{d} \odot \mathbf{v})+b_{y}\right) \\ =\exp \left(\frac{1}{2} \boldsymbol{W}_{y,:}^{\top} \mathbf{v}+b_{y}\right)\end{array}
$$
weight scaling rule은 비선형성이 있는 deep 모델에 대한 근사치일 뿐이다. 비록 근사치가 이론적으로 특징되어지지 않지만, 경험적으로 잘 작동하는 경우가 많다.
&lt;br /&gt;&lt;br /&gt;

&lt;span style=&quot;font-weight:700; font-size:1.3em;  margin-right: 1em;&quot;&gt;
Advantages of Dropout
&lt;/span&gt;
&lt;br /&gt;&lt;br /&gt;

Srivastava et al. (2014)에서는 weight decay, filter norm constraints, sparse activity regularization과 같은 계산적으로 inexpensive한 표준 정규화 방법보다 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;dropout이 더 효과적&lt;/b&gt;이라는 것을 보였다. 드랍아웃의 장점은 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;계산적으로 매우 cheap&lt;/b&gt;하다는 것이다. 트레이닝을 할 때 드랍아웃을 사용하는 것은 example 업데이트당 O(n)계산만 하면 된다. 또한 역전파(back propagation) 단계까지 이진수를 저장하기 위해 O(n) 메모리가 요구된다. 또 다른 중요한 장점은 사용할 수 있는 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;모델이나 트레이닝 절차의 타입을 제한하지 않는다는 것&lt;/b&gt;이다. 분포로 표현한 거의 모든 모델에서 잘 작동하고 stochastic gradient descent로 트레이닝 될 수 있다. 

&lt;br /&gt;&lt;br /&gt;

dropout의 상당 부분은 hidden units에 masking noise가 적용된다는 사실에서 발생한다는 점을 이해하는 것이 중요하다. 이것은 입력값의 raw values 보다 information content에 대한 고도의 지능적이고 적응적인 destruction 형태로 볼 수 있다. 원래 값보다 추출된 특징을 파괴하면 destruction 프로세스가 지금까지 획득한 입력 분포에 대한 모든 지식을 사용할 수 있다. 
&lt;/div&gt;
</description>
        <pubDate>Sat, 11 Apr 2020 18:00:08 +0000</pubDate>
        <link>http://munjeongkang.github.io/ANN5/</link>
        <guid isPermaLink="true">http://munjeongkang.github.io/ANN5/</guid>
        
        
        <category>수업</category>
        
      </item>
    
      <item>
        <title>인공신경망 - Parameter Norm Penalties</title>
        <description>&lt;hr /&gt;

&lt;div style=&quot;font-weight:500; font-size:1.0em; margin-left: 1em; margin-right: 1em;text-align:justify; &quot;&gt;
&lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;정규화&lt;/b&gt;는 딥러닝의 출현 이전에도 수십년 동안 사용되어 왔다. 선형 회귀모형이나 로지스틱 회귀모형 같은 선형 모델은 간단하고 효과적인 정규화가 가능하다. 많은 정규화 방법은 목적함수 $J$에 파라미터 norm penalty $\Omega(\theta)$를 추가하여 모델의 capacity를 제한하는 것에 기초한다. 정규화된 목적함수는 다음과 같다. 
&lt;p align=&quot;center&quot;&gt;
$$
\tilde{J}(\boldsymbol{\theta} ; \boldsymbol{X}, \boldsymbol{y})=J(\boldsymbol{\theta} ; \boldsymbol{X}, \boldsymbol{y})+\alpha \Omega(\boldsymbol{\theta}), \quad \text { where } \alpha \in[0, \infty)
$$
&lt;/p&gt;
$\alpha$를 0으로 설정하면 정규화가 되지 않고 $\alpha$의 값이 클수록 더 정규화된다. &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;parameter norm&lt;/b&gt; $\Omega$에 대해 다른 솔루션이 더 선호될 수 있다. 일반적으로 각 계층에서 affine 변환의 가중치에 대해서만 패널티를 주고 편차(bias)를 정규화하지 않는 파라미터 norm penalty $\Omega$를 사용한다. 편차를 정확하게 fit하기 위해 가중치보다 더 적은 데이터가 필요하고 편차 파라미터 정규화는 상당한 underfitting 양을 도입할 수 있다. 
&lt;br /&gt;&lt;br /&gt;
&lt;span style=&quot;font-weight:700; font-size:1.3em;  margin-right: 1em;&quot;&gt;
$L^2$ Parameter Regularization
&lt;/span&gt;
&lt;br /&gt;&lt;br /&gt;
$L^2$ parameter norm penalty는 흔히 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;weight decay&lt;/b&gt;로 알려져 있다. 
$$
\begin{array}{c}\Omega(\boldsymbol{\theta})=\frac{1}{2}\|\boldsymbol{w}\|_{2}^{2} \\ \tilde{J}(\boldsymbol{w} ; \boldsymbol{X}, \boldsymbol{y})=\frac{\alpha}{2} \boldsymbol{w}^{\top} \boldsymbol{w}+J(\boldsymbol{w} ; \boldsymbol{X}, \boldsymbol{y}) \\ \nabla_{\boldsymbol{w}} \tilde{J}(\boldsymbol{w} ; \boldsymbol{X}, \boldsymbol{y})=\alpha \boldsymbol{w}+\nabla_{\boldsymbol{w}} J(\boldsymbol{w} ; \boldsymbol{X}, \boldsymbol{y})\end{array}
$$
single gradient step을 수행하여 가중치를 업데이트 하는 방법은 다음과 같다. 
$$

\begin{array}{l}\boldsymbol{w} \leftarrow \boldsymbol{w}-\epsilon\left(\alpha \boldsymbol{w}+\nabla_{\boldsymbol{w}} J(\boldsymbol{w} ; \boldsymbol{X}, \boldsymbol{y})\right) \\ \boldsymbol{w} \leftarrow(1-\epsilon \alpha) \boldsymbol{w}-\epsilon \nabla_{\boldsymbol{w}} J(\boldsymbol{w} ; \boldsymbol{X}, \boldsymbol{y})\end{array}
$$

정규화되지 않은 트레이닝 비용을 최소화하는 가중치 값과 인접한 목적 함수에 대한 2차(quadratic) 근사를 만들어 분석을 단순하게 할 수 있다. 여기서 $H$는 $w^*$에서 평가된 $w$에 관한 $J$의 헤시안(Hessian) 행렬이다. 
$$
\begin{aligned} 
&amp;amp;\boldsymbol{w}^{*}=\arg \min _{\boldsymbol{w}} J(\boldsymbol{w}) \\
&amp;amp;\hat{J}(\boldsymbol{\theta}) =J\left(\boldsymbol{w}^{*}\right)+\frac{1}{2}\left(\boldsymbol{w}-\boldsymbol{w}^{*}\right)^{\top} \boldsymbol{H}\left(\boldsymbol{w}-\boldsymbol{w}^{*}\right) 
\end{aligned}
$$
gradient가 0일 때 $\hat{J}$가 최소가 된다. 
$$
\nabla_{\boldsymbol{w}} \hat{J}(\boldsymbol{w})=\boldsymbol{H}\left(\boldsymbol{w}-\boldsymbol{w}^{*}\right)
$$
이제 정규화된 $\hat{J}$의 최소값을 다음과 같이 구할 수 있게 된다. 
$$
\begin{array}{c}\alpha \tilde{\boldsymbol{w}}+\boldsymbol{H}\left(\tilde{\boldsymbol{w}}-\boldsymbol{w}^{*}\right)=0 \\ (\boldsymbol{H}+\alpha \boldsymbol{I}) \tilde{\boldsymbol{w}}=\boldsymbol{H} \boldsymbol{w}^{*} \\ \tilde{\boldsymbol{w}}=(\boldsymbol{H}+\alpha \boldsymbol{I})^{-1} \boldsymbol{H} \boldsymbol{w}^{*}\end{array}
$$
$\boldsymbol{H}=Q \Lambda Q^{\top}$로 분해(decompose) 할 수 있다. 
$$
\begin{aligned} \tilde{w} &amp;amp;=\left(Q \Lambda Q^{\top}+\alpha I\right)^{-1} Q \Lambda Q^{\top} w^{*} \\ &amp;amp;=\left[Q(\Lambda+\alpha I) Q^{\top}\right]^{-1} Q \Lambda Q^{\top} w^{*} \\ &amp;amp;=Q(\Lambda+\alpha I)^{-1} \Lambda Q^{\top} w^{*} \end{aligned}
$$
weight decay의 효과는 $\boldsymbol{H}$의 고유벡터(eigenvector)로 정의된 축을 따라서 $w^{*}$를 rescale하는 것이다. $\boldsymbol{H}$의 i번째 고유벡터로 정렬된 $w^*$의 성분은 $\lambda_i / (\lambda_i+\alpha)$ 의 인수로 재조정된다. $\boldsymbol{H}$의 고유값(eigenvalue)이 상대적으로 큰 방향을 따르면 (ex. $\lambda_i &amp;gt;&amp;gt; \alpha$) 정규화의 효과는 상대적으로 작아진다. 그러나 $\lambda_i &amp;lt;&amp;lt; \alpha$인 성분의 크기는 거의 0에 가까울 정도로 줄어들 것이다. 
&lt;br /&gt;&lt;br /&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/post_img/AN7.png&quot; width=&quot;400&quot; height=&quot;300&quot; /&gt;
&lt;/p&gt;

&lt;span style=&quot;font-weight:700; font-size:1.3em;  margin-right: 1em;&quot;&gt;
$L^1$ Regularization
&lt;/span&gt;
&lt;br /&gt;&lt;br /&gt;
$L^2$ weight decay가 weight decay의 가장 흔한 형식인 반면에, 모델 파라미터의 사이즈를 패널라이즈(penalize)하는 다른 방법도 있다. 그것은 바로 다음과 같이 $L^1$ 정규화를 사용하는 것이다. 
$$
\begin{array}{c}\Omega(\boldsymbol{\theta})=\|\boldsymbol{w}\|_{1}=\sum\left|w_{i}\right| \\ \tilde{J}(\boldsymbol{w} ; \boldsymbol{X}, \boldsymbol{y})=\alpha\|\boldsymbol{w}\|_{1}+J(\boldsymbol{w} ; \boldsymbol{X}, \boldsymbol{y}) \\ \nabla_{w} \tilde{J}(\boldsymbol{w} ; \boldsymbol{X}, \boldsymbol{y})=\alpha \operatorname{sign}(\boldsymbol{w})+\nabla_{w} J(\boldsymbol{X}, y ; \boldsymbol{w})\end{array}
$$
$H=\operatorname{diag}\left(\left[H_{1,1}, \ldots, H_{n, n}\right]\right)$와 같이 헤시안이 대각(diagonal)이라는 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;더욱 간단한 가정&lt;/b&gt;을 한다. 이 가정은 입력 특징들 사이의 모든 상관관계(correlation)를 제거하기 위해 선형회귀 문제에 대한 데이터가 전처리된 경우에 적용된다.
&lt;br /&gt;&lt;br /&gt;
$L^1$ 정규화된 목적 함수의 2차 근사는 다음과 같이 파라미터에 걸쳐 합(sum)으로 분해된다. 
$$
\hat{J}(\boldsymbol{w} ; \boldsymbol{X}, \boldsymbol{y})=J\left(\boldsymbol{w}^{*} ; \boldsymbol{X}, \boldsymbol{y}\right)+\sum_{i}\left[\frac{1}{2} H_{i, i}\left(\boldsymbol{w}_{i}-\boldsymbol{w}_{i}^{*}\right)^{2}+\alpha\left|w_{i}\right|\right]
$$
비용함수의 근사를 최소화하는 문제는 다음과 같은 형태로 각 차원 $i$에 대한 분석적인 솔루션을 가진다. 
$$
w_{i}=\operatorname{sign}\left(w_{i}^{*}\right) \max \left\{\left|w_{i}^{*}\right|-\frac{\alpha}{H_{i, i}}, 0\right\}
$$

모든 $i$에 대해 $w^*_i &amp;gt; 0$인 상황을 고려해보자.

&lt;ol&gt;
&lt;li&gt;$w^*_i \le \alpha / H_{i,i}$인 경우 &lt;br /&gt;
여기서 $w_i = 0$ 이다. 정규화된 목적합수에 대한 $J(w;X,y)$의 contribution이 $L^1$ 정규화에 의해 $i$ 방향으로 overwhelmed 되기 때문에 발생한다.  &lt;/li&gt;
&lt;li&gt;$w^*_i &amp;gt; \alpha / H_{i,i}$인 경우 &lt;br /&gt;
이 경우는 정규화가 $w_i$의 최적값을 0으로 이동시키는 것이 아니라 $\alpha H_{i,i}$와 같은 거리만큼 그 방향으로만 이동시킨다.&lt;/li&gt;
&lt;/ol&gt;

$L^2$ 정규화와 비교하여 $L^1$ 정규화는 더 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;희소한(sparse)&lt;/b&gt;한 솔루션을 준다. $L^1$ 정규화에 의해 유도된 희소성질 (sparsity property)은 특징 선택 (feature selection) 매커니즘으로 광범위하게 사용되어왔다. 
&lt;/div&gt;
</description>
        <pubDate>Sat, 11 Apr 2020 18:00:08 +0000</pubDate>
        <link>http://munjeongkang.github.io/ANN4/</link>
        <guid isPermaLink="true">http://munjeongkang.github.io/ANN4/</guid>
        
        
        <category>수업</category>
        
      </item>
    
      <item>
        <title>인공신경망 - Output Units</title>
        <description>&lt;hr /&gt;

&lt;div style=&quot;font-weight:500; font-size:1.0em; margin-left: 1em; margin-right: 1em;text-align:justify; &quot;&gt;
비용 함수의 선택은 출력 단위(output unit)의 선택과 밀접하게 연결된다. 대부분의 경우, 단순하게 데이터 분포와 모델 분포 사이의 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;cross-entropy&lt;/b&gt;를 사용한다. 우리는 feedforward 네트워크가 $h=f(x;\theta)$로 정의된 숨겨진 특징(hidden features)을 제공한다고 가정한다. 출력 계층(output layer)의 역할은 네트워크가 수행해야 하는 task를 완료하기 위하여 특징에 추가적인 변환을 제공하는 것이다.
&lt;br /&gt;&lt;br /&gt;
&lt;span style=&quot;font-weight:700; font-size:1.3em;  margin-right: 1em;&quot;&gt;
Linear Units for Gaussian Output Distributions
&lt;/span&gt;
&lt;br /&gt;&lt;br /&gt;
간단한 출력 단위 중 하나는 비선형성(nonlinearity)이 없는 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;affine 변환&lt;/b&gt;에 기초한 것이다. 이것들은 주로 선형 단위로 불리며 특징 $h$가 주어질 때, 선형 출력 단위의 계층은 벡터 $\hat{y}=W^{\top} h+b$를 생성한다. 선형 출력 계층들은 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;조건부 가우시안 분포&lt;/b&gt;인 $p(\boldsymbol{y} | \boldsymbol{x})=\mathcal{N}(\boldsymbol{y} ; \hat{\boldsymbol{y}}, \boldsymbol{I})$의 평균을 생성하는데 사용된다. 선형 단위는 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;포화 상태(saturate)가 아니기&lt;/b&gt; 때문에 기울기(gradient) 기반 최적화 알고리즘에는 별다른 어려움이 없으며 다양한 최적화 알고리즘과 함께 사용될 수 있다. 
&lt;br /&gt;&lt;br /&gt;

&lt;span style=&quot;font-weight:700; font-size:1.3em;  margin-right: 1em;&quot;&gt;
Sigmoid Units for Bernoulli Output Distributions
&lt;/span&gt;
&lt;br /&gt;&lt;br /&gt;
많은 작업에서 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;이진 변수&lt;/b&gt;(binary variable)인 $y$값을 예측해야 한다. 베르누이 분포는 단 하나의 수로 정의되므로 신경망(neural net)은 $P(y=1|x)$만 예측하면 된다. 이 숫자가 유효한 확률이 되려면 [0,1]간격에 있어야 하고 이 제약을 만족하려면 신중하게 디자인 할 필요가 있다. 유효한 확률을 얻기 위해 선형 단위를 사용하고 그 값을 한계점(threshold)으로 사용한다고 다음과 같이 가정한다.&lt;br /&gt;
&lt;p align=&quot;center&quot;&gt;
&lt;br /&gt;
 $P(y=1 | \boldsymbol{x})=\max \left\{0, \min \left\{1, \boldsymbol{w}^{\top} \boldsymbol{h}+b\right\}\right\}$
 &lt;/p&gt;
경사하강법(gradient decent)으로는 이를 매우 효과적으로 훈련시킬 수 없다. $w^{\top} h+b$가 단위 구간을 벗어나면 파라미터에 대한 모델의 아웃풋 기울기가 0이 되기 때문이다. 대신 모델이 잘못된 답을 줄 때마다 항상 강한(strong) 기울기를 보장하는 다른 접근법을 사용하는 것이 좋다. &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;시그모이드 출력 단위&lt;/b&gt;는 $\hat{y}=\sigma\left(\boldsymbol{w}^{\top} \boldsymbol{h}+b\right)$로 정의되며 $\sigma$는 로지스틱 시그모이드 함수이다. 
&lt;br /&gt;&lt;br /&gt;
시그모이드 출력 단위는 두 개의 구성 요소를 가지고 있다고 생각할 수 있다. 
&lt;ol&gt;
&lt;li&gt;$z=w^{\top} h+b$를 계산하기 위해 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;선형 레이어&lt;/b&gt;를 사용하는 것&lt;/li&gt;
&lt;li&gt;$z$를 확률로 변환하기 위해 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;시그모이드 활성화(activation) 함수&lt;/b&gt;를 사용하는 것&lt;/li&gt;
&lt;/ol&gt;
만약 비정규화된(unnormalized) 로그 확률이 $y$와 $z$에서 선형이라고 가정한다면 비정규화된 확률을 얻기 위해 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;지수화(exponentiate)&lt;/b&gt;할 수 있다. $z$의 시그모이드 변환에 의해 베르누이 분포 산출을 위한 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;정규화&lt;/b&gt; 과정은 다음과 같다. 
&lt;br /&gt;&lt;br /&gt;
&lt;p align=&quot;center&quot;&gt;
$\begin{aligned} 
\log \tilde{P}(y) &amp;amp;=y z \\ 
\tilde{P}(y) &amp;amp;=\exp (y z) \\ 
P(y) &amp;amp;=\frac{\exp (y z)}{\sum_{y^{\prime}=0}^{1} \exp \left(y^{\prime} z\right)} \\ 
P(y) &amp;amp;=\sigma((2 y-1) z) 
\end{aligned}$
&lt;/p&gt;
로그 공간에서 확률을 예측하는 이 접근법은 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;최대 우도(maximum likelihood)&lt;/b&gt; 학습에 사용하는 것이 보통이다. 왜냐하면 최대 우도에 사용되는 비용 함수가 $ \log P(y|x)$이기 때문에, 비용함수에서 로그는 시그모이드의 exp를 없애준다. 이러한 효과가 없다면, 시그모이드의 포화상태는 gradient 기반 학습의 진전을 막았을 것이다. 
&lt;br /&gt;&lt;br /&gt;
시그모이드에 의해 파라미터화되는 베르누이의 최대 우도 학습에 대한 손실 함수(loss function)는 다음과 같다. $\zeta$ 는 softplus 함수이다.
&lt;br /&gt;&lt;br /&gt;
&lt;p align=&quot;center&quot;&gt;
$ \begin{aligned} 
J(\boldsymbol{\theta}) &amp;amp;=-\log P(y | \boldsymbol{x}) \\ 
&amp;amp;=-\log \sigma((2 y-1) z) \\ 
&amp;amp;=\zeta((1-2 y) z) 
\end{aligned}$
&lt;/p&gt;
$(1-2y)z$가 very negative(매우 작은 음수)한 경우만 포화되므로 포화상태는 모델이 이미 올바른 정답을 가지고 있을 때만 발생한다. 즉, $y=1$ 이고 $z$가 very positive(매우 큰 양수) 하거나 $y=0$이고 $z$가 very negative 한 경우만 발생한다. $z$가 잘못된 사인을 가질 때, softplus 함수에 대한 인수(argument) $(1-2y)z$는 $|z|$로 단순화될 수 있다. 
&lt;br /&gt;&lt;br /&gt;
&lt;span style=&quot;font-weight:700; font-size:1.3em;  margin-right: 1em;&quot;&gt;
Softmax Units for Multinoulli Output Distributions
&lt;/span&gt;
&lt;br /&gt;&lt;br /&gt;
$n$개의 값을 가지는 이산 변수의 경우로 일반화하기 위해 $\hat{y}_{i}=P(y=i | \boldsymbol{x})$에 대한 벡터 $\hat{y}$가 필요하다. 먼저 선형 계층이 비정규화된 로그 확률을 다음과 같이 예측한다.
 &lt;p align=&quot;center&quot;&gt;
&lt;br /&gt;
 $z=W^{\top}h+b \quad $ where $z_{i}=\log \tilde{P}(y=i | \boldsymbol{x})$
 &lt;/p&gt;
소프트맥스 함수는 원하는 $\hat{y}$를 얻기 위해 $z$를 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;지수화&lt;/b&gt;하고 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;정규화&lt;/b&gt;할 수 있다. 
&lt;p align=&quot;center&quot;&gt;
&lt;br /&gt;
 $\operatorname{softmax}(\boldsymbol{z})_{i}=\frac{\exp \left(z_{i}\right)}{\sum_{j} \exp \left(z_{j}\right)}$
 &lt;/p&gt;
이를 다음과 같이 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;최대화&lt;/b&gt; 하길 원한다. 
&lt;p align=&quot;center&quot;&gt;
&lt;br /&gt;
 $ \begin{aligned} 
 \log P(\mathrm{y}=i ; z)&amp;amp;=\log \operatorname{softmax}(z)_{i} \\
 \log \operatorname{softmax}(\boldsymbol{z})_{i}&amp;amp;=z_{i}-\log \sum_{j} \exp \left(z_{j}\right)
 \end{aligned}
 $
 &lt;/p&gt;
 두번째 항은 $\max_j z_j$로 근사될 수 있다. 만약 올바른 답이 소프트맥스에 대한 가장 큰 입력을 이미 가지고 있다면, $-z_i$ 항과 $\log \sum_{j} \exp \left(z_{j}\right) \approx \max _{j} z_{j}=z_{i}$ 항은 거의 취소된다. 이 예제는 전체 트레이닝 비용에는 기여하지 못하지만 아직 정확하게 분류되지 않은 다른 예제에 의해 지배될(dominated) 것이다. 
 &lt;br /&gt;&lt;br /&gt;

신경과학적인(neuroscientific) 관점에서 소프트 맥스를 단위들 사이의 경쟁의 형태로 만든다는 생각은 흥미롭다. 
&lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;소프트맥스 아웃풋의 합은 항상 1&lt;/b&gt;이기 때문에 한 단위 값이 증가하면 다른 단위 값은 감소한다. 이는 피질(cortex) 안에 있는 근처 뉴런사이에 존재하는 것으로 여겨지는 측면 억제(lateral inhibition)와 유사하다. &quot;소프트(soft)&quot;라는 용어는 소프트맥스가 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;연속&lt;/b&gt;이고 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;미분가능하다&lt;/b&gt;는 사실에서 유래하였으며, 소프트맥스 함수는 argmax의 softened 버전을 제공한다. 
&lt;br /&gt;&lt;br /&gt;

&lt;span style=&quot;font-weight:700; font-size:1.3em;  margin-right: 1em;&quot;&gt;
Other Output Types
&lt;/span&gt;
&lt;br /&gt;&lt;br /&gt;
신경망(neural network)은 우리가 원하는 거의 모든 종류의 출력계층을 일반화할 수 있다. &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;최대 우도 원리(principle)&lt;/b&gt;는 출력 계층에 대해 비용 함수를 좋게 설계하는 방법에 대한 가이드를 준다. 조건부 분포 $p(y|x;\theta)$를 정의한다면 최대우도원리는 비용 함수를 $\log p(y|x;\theta)$로 사용하도록 한다. 
&lt;br /&gt;&lt;br /&gt;
일반적으로 신경망은 함수 $f(x;\theta)$를 표현하는 것으로 생각할 수 있다. 이 함수의 아웃풋은 $y$ 값을 직접 예측하는 것은 아니다. 대신 $f(x;\theta)=\omega$가 $y$ 에 대한 분포의 파라미터를 제공한다. 손실함수는 $-\log p(y;\omega(x))$로 해석될 수 있다. 
&lt;br /&gt;&lt;br /&gt;
우리는 가끔 multimodal regression을 수행할 수도 있다. 이는 동일한 $x$값에 대해 y 스페이스에 여러개의 다른 peak들을 가질 수 있는 조건부 분포 $p(y|x)$에서 실제 값을 예측하는 것이다. 이 경우에는 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;Gaussian mixture&lt;/b&gt;를 아웃풋으로 하고 이런 신경망을 흔히 mixture density networks라고 한다. 
&lt;p align=&quot;center&quot;&gt;
$$
p(\boldsymbol{y} | \boldsymbol{x})=\sum_{i=1}^{n} p(\mathrm{c}=i | \boldsymbol{x}) \mathcal{N}\left(\boldsymbol{y} ; \boldsymbol{\mu}^{(i)}(\boldsymbol{x}), \boldsymbol{\Sigma}^{(i)}(\boldsymbol{x})\right)$$
&lt;/p&gt;
그러나 조건부 가우시안 혼합의 gradient 기반 최적화는 신뢰할 수 없다. 왜냐하면 수치적으로 불안정한 분산에 의한 division을 얻을 수 있기 때문이다. 특정한 예시에서 일부 분산이 작은 경우 매우 큰 gradient를 산출한다. 가우시안 혼합 아웃풋은 특히 물리적인 객체의 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;음성&lt;/b&gt;과 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;움직임&lt;/b&gt;의 생성 모델에 효과적이다. 아래 그림은 mixture density의 아웃풋이다. 
&lt;br /&gt;&lt;br /&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/post_img/AN6.png&quot; width=&quot;650&quot; height=&quot;300&quot; /&gt;
&lt;/p&gt;
&lt;/div&gt;
</description>
        <pubDate>Sat, 11 Apr 2020 18:00:08 +0000</pubDate>
        <link>http://munjeongkang.github.io/ANN3/</link>
        <guid isPermaLink="true">http://munjeongkang.github.io/ANN3/</guid>
        
        
        <category>수업</category>
        
      </item>
    
      <item>
        <title>인공신경망 - Capacity, Overfitting and Underfitting</title>
        <description>&lt;hr /&gt;

&lt;div style=&quot;font-weight:500; font-size:1.0em; margin-left: 1em; margin-right: 1em;text-align:justify; &quot;&gt;
&lt;span style=&quot;font-weight:700; font-size:1.3em;  margin-right: 1em;&quot;&gt;
일반화 (Generalization)
&lt;/span&gt;
&lt;br /&gt;&lt;br /&gt;
머신러닝에서는 이미 훈련된 모델에 사용된 입력값 뿐만 아니라 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;새로운 입력값&lt;/b&gt;에 대해서도 모델이 잘 작동하도록 하는 것이 중요하다. 새로운 입력값에도 모델이 잘 작동하는 능력을 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;일반화&lt;/b&gt;라고 한다. 최적화와 구분하여 머신 러닝에서는 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;test error&lt;/b&gt;라고도 불리는 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;generalization error(일반화 오류)&lt;/b&gt;가 낮기를 원한다. 따라서 트레이닝 에러뿐만 아니라 테스트 에러에 대한 주의도 필요하다. 
&lt;br /&gt;&lt;br /&gt;
훈련 데이터와 테스트 데이터는 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;data generating process&lt;/b&gt;(데이터 생성 과정)라 불리는 데이터셋에 대한 확률분포에 의해 생성된다. 일반적으로 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;i.i.d 가정&lt;/b&gt;을 사용한다. i.i.d 가정이란 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;independent&lt;/b&gt;(독립), &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;identically distributed&lt;/b&gt;(동일한 분포)를 뜻한다. 즉, 각각의 데이터셋은 독립이고 훈련 집합과 테스트 집합은 같은 확률 분포에서 나와 동일한 분포를 가진다는 것이다. 이 가정은 확률 분포로 데이터 생성 과정을 설명할 수 있게 해주며 모든 훈련 예제와 테스트 예제를 생성하기 위해 동일한 분포가 사용된다. &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;데이터 생성 분포&lt;/b&gt;를 공유한 것을 $p_{data}$라 부르고 이러한 확률적 체계와 i.i.d 가정은 트레이닝 에러와 테스트 에러 사이의 관계를 수학적으로 연구할 수 있게 해준다. 
&lt;br /&gt;&lt;br /&gt;

&lt;span style=&quot;font-weight:700; font-size:1.3em;  margin-right: 1em;&quot;&gt;
저적합 및 과적합 (Underfitting and Overfitting)
&lt;/span&gt;
&lt;br /&gt;&lt;br /&gt;
머신러닝 알고리즘이 얼마나 잘 작동하는지 결정하는 요소는 다음과 같다.  
&lt;ol&gt;
&lt;li&gt;트레이닝 에러가 작은가&lt;/li&gt;
&lt;li&gt;트레이닝 에러와 테스트 에러 사이의 차이가 작은가&lt;/li&gt;
&lt;/ol&gt;
이 두 가지 요소는 머신러닝의 두 가지 핵심 과제인 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;underfitting&lt;/b&gt;과 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;overfitting&lt;/b&gt;에 해당한다. 저적합은 모델이 트레이닝 셋에서 충분히 낮은 에러 값을 얻지 못할 때 발생하고 과적합은 트레이닝 에러와 테스트 에러 사이의 차이가 너무 클 때 발생한다. 즉, 저적합은 트레이닝이 부족한 경우에 발생하고 과적합은 트레이닝이 과하게 된 경우 발생한다. 
&lt;br /&gt;&lt;br /&gt;

&lt;span style=&quot;font-weight:700; font-size:1.3em;  margin-right: 1em;&quot;&gt;
용량 (Capacity)
&lt;/span&gt;
&lt;br /&gt;&lt;br /&gt;
머신러닝에서 모델에 있는 학습 파라미터의 수를 모델의 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;capacity&lt;/b&gt;라고 한다. capacity를 변경함으로써 모델의 적합 정도를 조절할 수 있고 capacity가 높아질수록 트레이닝 셋에 점점 맞춰지기 때문에 과적합될 가능성이 높아진다. 학습 알고리즘의 capacity는 솔루션으로 선택할 수 있는 함수의 집합인 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;가설 공간(hypothesis space)&lt;/b&gt;을 선택함으로써 제어할 수도 있다. 예를 들어 선형 함수가 아닌 다항식(polynomials)을 가설공간에 포함하여 선형 회귀를 일반화 할 수 있다. 이 경우에는 모델의 capacity가 증가한다.
&lt;br /&gt;&lt;br /&gt;
머신러닝 알고리즘은 일반적으로 task의 복잡성과 제공된 트레이닝 데이터의 양에 대한 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;capacity가 적절할 때 가장 잘 수행된다.&lt;/b&gt; capacity가 충분하지 않은 모델은 복잡한 task를 풀 수 없다. capacity가 높은 모델은 복잡한 task는 풀지만 필요 이상으로 capacity가 많아지면 과적합된다. 
&lt;br /&gt;&lt;br /&gt;
&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/post_img/AN.png&quot; width=&quot;650&quot; height=&quot;300&quot; /&gt;
&lt;/p&gt;
사실상 모델의 capacity를 바꿀 수 있는 방법은 많이 있다. 모델이 training objective를 줄이기 위해 파라미터를 변경할 때, &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;학습 알고리즘이 선택할 수 있는 함수의 family&lt;/b&gt;를 정한다. 이를 모델의 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;표현 용량(representational capacity)&lt;/b&gt;이라고 부른다. 많은 경우, 함수의 family에서 가장 좋은 함수를 찾는 것은 매우 어려운 최적화 문제이다. 사실상 학습 알고리즘은 가장 좋은 함수를 찾지 않지만 트레이닝 에러는 상당히 줄인다. 이러한 추가적인 제한은 학습 알고리즘의 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;유효 용량(effective capacity)&lt;/b&gt;이 모델 family의 표현 용량 보다 작을 수 있음을 의미한다. 
&lt;br /&gt;&lt;br /&gt;

&lt;span style=&quot;font-weight:700; font-size:1.3em;  margin-right: 1em;&quot;&gt;
일반화와 용량 (Generalization and Capacity)
&lt;/span&gt;
&lt;br /&gt;&lt;br /&gt;
단순한 함수들은 일반화될 가능성이 더 높지만 낮은 트레이닝 에러를 얻기 위해서는 충분히 복잡한 가설을 선택해야 한다. 
일반적으로 트레이닝 에러는 모델 capacity가 증가함에 따라 가능한 최소 에러에 근접할 때까지 줄어든다. 일반화 에러는 모델 capacity의 함수로써 U자형 커브 모양을 가진다. 
&lt;br /&gt;&lt;br /&gt;
&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/post_img/AN2.png&quot; width=&quot;650&quot; height=&quot;300&quot; /&gt;
&lt;/p&gt;
임의의 high capacity의 가장 극단적인 경우에 도달하기 위해 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;비모수적(non-parametric)&lt;/b&gt; 모델의 개념을 소개한다. 모수적(parametric) 모델은 어떤 데이터가 발견되기 전까지 유한하고 고정된 사이즈의 파라미터 벡터로 표현된 함수를 학습한다. 비모수적 모델은 이러한 제한이 없으며 최근접회귀(nearest neighbor regression)를 예로 들 수 있다. 이상적인 모델은 데이터를 생성하는 실제 확률 분포를 간단히 아는 oracle이다. 그러나 분포에 노이즈가 있기 때문에 약간의 에러가 발생할 수 있다. 실제 분포로 부터 예측하는 oracle에 의해 발생한 에러를 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;베이즈 에러(Bayes error)&lt;/b&gt;라고 한다. 
&lt;br /&gt;&lt;br /&gt;

트레이닝 에러와 일반화 에러는 트레이닝셋의 크기에 따라 달라진다. 기대되는(expected) &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;일반화 에러는 트레이닝 example의 수가 증가한다고 증가할 수 없다.&lt;/b&gt; 비모수적 모델에서는 데이터가 많을수록 가능한 가장 좋은 에러를 얻을 때까지 더 좋은 일반화를 만든다. 최적 capacity보다 작은 어떤 고정된 모수 모델은 베이즈 에러를 초과하는 에러값에 근접할 것이다. 모델은 최적의 capacity를 가질 수 있지만 여전히 트레이닝 에러와 일반화 에러 사이의 큰 차이를 가진다. 
&lt;br /&gt;&lt;br /&gt;
&lt;div style=&quot;border: 1px; float: right;margin-left: 1em; margin-right: 1em; &quot;&gt;
&lt;img src=&quot;/images/post_img/AN4.png&quot; width=&quot;290&quot; height=&quot;250&quot; /&gt;
&lt;/div&gt;
&lt;div style=&quot;border: 1px; margin-left: 2em; margin-right: 1em; &quot;&gt;
&lt;img src=&quot;/images/post_img/AN3.png&quot; width=&quot;290&quot; height=&quot;250&quot; /&gt;
&lt;/div&gt;
&lt;br /&gt;&lt;br /&gt;

&lt;span style=&quot;font-weight:700; font-size:1.3em;  margin-right: 1em;&quot;&gt;
No Free Lunch Theorem
&lt;/span&gt;
&lt;br /&gt;&lt;br /&gt;
&#39;공짜 점심은 없다&#39; 라는 이론은 머신러닝 알고리즘이 다른 어떤 것보다 일반적으로 낫지 않음을 뜻한다. 즉, 머신러닝이 만능은 아니라는 것이다. 모든 분류 알고리즘은 이전에 관찰되지 않은 point를 분류할 때, 가능한 모든 데이터 생성 분포에 대한 평균으로써 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;동일한 오류 비율&lt;/b&gt;을 가진다. 다행히도 이런 결과는 가능한 모든 데이터 생성 분포에 대해 평균을 낼 때만 유지되므로 실제 응용사례에서 접하는 확률 분포의 종류에 대한 가정을 만들면, 이러한 분포에서 잘 수행되는 학습 알고리즘을 설계할 수 있다. 
&lt;br /&gt;&lt;br /&gt;
머신러닝 연구의 목표는 일반적인 학습 알고리즘이나 절대적으로 가장 좋은 학습 알고리즘을 찾는 것이 아니다. 대신, AI 에이전트가 경험하는 실제 세계와 어떤 분포가 관련되는지 이해하고 우리가 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;관심을 갖는 분포&lt;/b&gt;에서 도출된 데이터로부터 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;어떤 종류의 머신러닝 알고리즘이 잘 수행되는지 파악하는 것&lt;/b&gt;이다. 
&lt;br /&gt;&lt;br /&gt;

&lt;span style=&quot;font-weight:700; font-size:1.3em;  margin-right: 1em;&quot;&gt;
정규화 (Regularization)
&lt;/span&gt;
&lt;br /&gt;&lt;br /&gt;
No Free Lunch Theorem은 머신러닝 알고리즘이 구체적인 task를 잘 수행하도록 디자인 해야함을 시사한다. 지금까지 학습 알고리즘을 수정하는 유일한 방법은 솔루션의 가설 공간에 참수를 추가하거나 제거함으로써 모델의 표현 용량을 증가시키거나 감소시키는 것이었다. 어떤 종류의 함수에서 솔루션을 도출할 수 있게 선택하고 이러한 함수의 양을 조절함으로써 알고리즘의 성능을 제어할 수 있다. 
&lt;br /&gt;&lt;br /&gt;

또한 가설 공간에서 다른곳으로 하나의 솔루션에 대한 선호도(preference)를 줄 수 있다. 예를 들어 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;weight decay&lt;/b&gt; ($J(w)=MSE_{trin} + \lambda w^Tw$) 가 있다. 트레이닝 데이터 적합에 대한 가중치를 선택할 수 있는 것인데 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;weight decay의 값이 커질수록&lt;/b&gt; 가중치 값이 작아져 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;과적합 현상을 해소&lt;/b&gt;할 수 있지만, weight decay 값을 너무 크게 하면 저적합 현상이 발생하므로 적당한 값을 사용해야 한다. 좀더 일반적으로 함수 $f(x;\theta)$ 를 비용함수에 정규화(regularizer)라 불리는 패널티로 추가해줌으로써 모델을 정규화할 수 있다. weight decay의 경우 regularizer는 $\Omega (w) = w^Tw$ 이다. 
&lt;br /&gt;&lt;br /&gt;
&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/post_img/AN5.png&quot; width=&quot;650&quot; height=&quot;300&quot; /&gt;
&lt;/p&gt;

다른 솔루션에 대한 선호도를 표현하는 방법은 암시적으로(implicily)나 명백하게(explicitly) 많이 있다. 이와 같이 다른 접근방법들은 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;정규화(regularization)&lt;/b&gt;로 알려져 있다. 정규화는 트레이닝 에러가 아닌 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;일반화 에러를 줄이기 위한 학습 알고리즘&lt;/b&gt;이며 머신러닝의 핵심 관심사 중 하나이다. 앞서 살펴본 공짜 점심은 없다는 이론은 최고의(best) 머신러닝 알고리즘은 없으며, 특히 가장 좋은 형태의 정규화는 없다는 것을 확실하게 보여준다. 
&lt;/div&gt;
</description>
        <pubDate>Fri, 10 Apr 2020 18:00:08 +0000</pubDate>
        <link>http://munjeongkang.github.io/ANN2/</link>
        <guid isPermaLink="true">http://munjeongkang.github.io/ANN2/</guid>
        
        
        <category>수업</category>
        
      </item>
    
      <item>
        <title>인공신경망 - Learning Algorithms. The Task, T</title>
        <description>&lt;hr /&gt;

&lt;div style=&quot;font-weight:500; font-size:1.0em; margin-left: 1em; margin-right: 1em;text-align:justify; &quot;&gt;

&lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;머신러닝(machine learning)&lt;/b&gt;은 사람에 의해 디자인된 프로그램(fixed programs)으로 풀기 너무 어려운 일(task)을 다룰 수 있도록 해준다. 스스로 배우는 과정은 task가 아니며 머신러닝 task는 일반적으로 머신러닝 시스템이 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;예시&lt;/b&gt;(example)를 어떻게 처리해야하는지에 관한 것이다. 하나의 예시로 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;특징&lt;/b&gt;(features) $x_i$를 모으는 것이 있다. 이를 특징 추출(feature collection)이라고 하며 이미지의 특징은 주로 픽셀(pixel)의 값이다.
&lt;br /&gt;&lt;br /&gt;
&lt;span style=&quot;font-weight:700; font-size:1.3em;  margin-right: 1em;&quot;&gt;
분류 (Classification)
&lt;/span&gt;
&lt;br /&gt;&lt;br /&gt;
입력값을 $k$개의 카테고리로 구체화하기 위한 방법이다. 분류의 예시로 객체인식 (object recognition)이 있으며 이는 이미지가 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;input&lt;/b&gt;으로 주어졌을 때 이미지 속 객체를 인식하는 수치적인(numeric) 코드가 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;output&lt;/b&gt;으로 나오는 것이다. 알고리즘을 학습하는 것은 $f : \mathbb{R}^{n} \rightarrow\{1, \ldots, k\}$와 같이 함수를 만드는 것이고, $y=f(x)$일 때 input인 vector $x$에 의해 나온 output $y$에 따라 카테고리가 할당된다. 
&lt;br /&gt;&lt;br /&gt;
&lt;span style=&quot;font-weight:700; font-size:1.3em;  margin-right: 1em;&quot;&gt;
누락된 입력이 있는 분류 (Classification with Missing Inputs)
&lt;/span&gt;
&lt;br /&gt;&lt;br /&gt;
누락된 입력이 있는 경우, 하나의 분류 함수만 사용하지 말고 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;함수 집합&lt;/b&gt; (Set of Functions)으로 알고리즘을 학습시켜야 한다. 함수 집합은 누락된 입력에 대해 각각 다른 부분집합을 가지는 $x$에 대한 함수들이다. 만약 함수 집합의 크기가 크다면 관련된 모든 변수를 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;확률 분포&lt;/b&gt;로 학습시키는 것이 누락된 변수를 무시할 수 있어 더 좋다. $n$개의 입력변수에 대해 $2^n$개의 분류 함수를 모두 포함할 수도 있지만 알고리즘을 학습시키기 위해 확률 분포가 결합된 단일 함수가 필요하다. 
&lt;br /&gt;&lt;br /&gt;
&lt;span style=&quot;font-weight:700; font-size:1.3em;  margin-right: 1em;&quot;&gt;
회귀분석 (Regression)
&lt;/span&gt;
&lt;br /&gt;&lt;br /&gt;
주어진 입력값의 수치적인 값을 예측하기 위한 방법이다 ($f : \mathbb{R}^{n} \rightarrow \mathbb{R}$). &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;Output의 포멧이 다르다는 점&lt;/b&gt;을 제외하고 분류(classification)와 비슷하다. 예를 들어 피보험자가 부담하게 될 예상 청구 금액 등을 예측하는데 사용할 수 있다. 
&lt;br /&gt;&lt;br /&gt;
&lt;span style=&quot;font-weight:700; font-size:1.3em;  margin-right: 1em;&quot;&gt;
전사 (Transcription)
&lt;/span&gt;
&lt;br /&gt;&lt;br /&gt;
상대적으로 구조적이지 않은 종류의 데이터를 개별적인 원문(textual) 형식으로 바꾸는 것이다. 예시로는 광학적 문자 인식 (optical character recognition), 음성 인식 (speech recognition) 등이 있다.  
&lt;br /&gt;&lt;br /&gt;
&lt;span style=&quot;font-weight:700; font-size:1.3em;  margin-right: 1em;&quot;&gt;
기계번역 (Machine Translation)
&lt;/span&gt;
&lt;br /&gt;&lt;br /&gt;
입력값은 이미 어떤 언어 규칙 순서로 구성되어 있고 컴퓨터 프로그램은 이를 다른 언어 규칙 순서로 변환해야한다. 
&lt;br /&gt;&lt;br /&gt;
&lt;span style=&quot;font-weight:700; font-size:1.3em;  margin-right: 1em;&quot;&gt;
구조적 출력 (Structured Output)
&lt;/span&gt;
&lt;br /&gt;&lt;br /&gt;
Structured Ouput은 각 요소들 사이의 중요한 관계를 가지는 벡터나 다수의 값을 포함하는 또 다른 데이터 구조이다. 이것은 넓은 범주로 전사(transcription)와 번역(translation) 작업을 포함한다. 예를 들어 구문 분석이나, 픽셀별로 이미지를 분할하는 것 등이 있다.   
&lt;br /&gt;&lt;br /&gt;
&lt;span style=&quot;font-weight:700; font-size:1.3em;  margin-right: 1em;&quot;&gt;
이상 감지 (Anonmaly Detection)
&lt;/span&gt;
&lt;br /&gt;&lt;br /&gt;
컴퓨터 프로그램은 일련의 사건이나 객체에 대해 살피면서 비정상적이거나 이례적인 것을 찾아 표시한다. 예를 들어 신용카드 사기를 감지하는 것이 있다. 
&lt;br /&gt;&lt;br /&gt;
&lt;span style=&quot;font-weight:700; font-size:1.3em;  margin-right: 1em;&quot;&gt;
합성 및 샘플링 (Synthesis and Sampling)
&lt;/span&gt;
&lt;br /&gt;&lt;br /&gt;
트레이닝 데이터와 유사한 새로운 예제를 생성하는 방법이다. 예를 들어 음성 합성 (speech synthesis) 등이 있고 구조적 출력 작업의 일종이지만 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;추가적인 조건(qualification)&lt;/b&gt;이 있다. 각 인풋에 대해 유일한 아웃풋은 없고 아웃풋이 더 자연스럽고 사실적으로 보이도록 많은 양의 변화를 준다.   
&lt;br /&gt;&lt;br /&gt;
&lt;span style=&quot;font-weight:700; font-size:1.3em;  margin-right: 1em;&quot;&gt;
누락값 대체 (Imputation of Missing Values)
&lt;/span&gt;
&lt;br /&gt;&lt;br /&gt;
&lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;새로운 예시 &lt;/b&gt;$x \in \mathbb{R}^n$가 주어지지만 $x$의 일부 항목 $x_i$가 누락되어 있다. 알고리즘은 누락된 항목값에 대한 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;예측을 포함&lt;/b&gt;해야한다. 
&lt;br /&gt;&lt;br /&gt;
&lt;span style=&quot;font-weight:700; font-size:1.3em;  margin-right: 1em;&quot;&gt;
노이즈 제거 (Denoising)
&lt;/span&gt;
&lt;br /&gt;&lt;br /&gt;
노이즈가 없는 clean example $x \in \mathbb{R}^n$에 알 수 없는 변형이 생겨 입력값에 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;변질된 example&lt;/b&gt; $\tilde{x} \in \mathbb{R}^{n}$이 포함되어 주어지는 경우가 있다. 따라서 변질된 $\tilde{x}$로 부터 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;clean&lt;/b&gt; $x$를 예측하거나 좀더 일반적으로 조건부 확률 $p(x|\tilde{x})$을 예측한다.
&lt;br /&gt;&lt;br /&gt;
&lt;span style=&quot;font-weight:700; font-size:1.3em;  margin-right: 1em;&quot;&gt;

Density Estimation or Probability Mass Function Estimation
&lt;/span&gt;
&lt;br /&gt;&lt;br /&gt;
함수 $ p_{model} : \mathbb{R}^n \rightarrow \mathbb{R}$에서 $p_{model}$은 $x$가 연속(continuous)일 경우 확률밀도함수(pdf), $x$가 이산(discrete)일 경우 확률질량함수(pmf)로 해석된다. example들이 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;어디에서 타이트하게 군집화되는지&lt;/b&gt;와 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;어디서 발생할 가능성이 낮은지&lt;/b&gt; 알아야 한다. 그러면 다른 task들도 해결할 수 있는 분포에 대한 계산을 수행할 수 있다.
&lt;br /&gt;&lt;br /&gt;

&lt;/div&gt;
</description>
        <pubDate>Fri, 10 Apr 2020 18:00:08 +0000</pubDate>
        <link>http://munjeongkang.github.io/ANN1/</link>
        <guid isPermaLink="true">http://munjeongkang.github.io/ANN1/</guid>
        
        
        <category>수업</category>
        
      </item>
    
      <item>
        <title>Agent Based Modeling - Prediction</title>
        <description>&lt;hr /&gt;

&lt;div style=&quot;font-weight:500; font-size:1.0em; margin-left: 1em; margin-right: 1em;text-align:justify; &quot;&gt;
&lt;span style=&quot;font-weight:700; font-size:1.3em;  margin-right: 1em;&quot;&gt;
Prediction
&lt;/span&gt;
&lt;br /&gt;&lt;br /&gt;
ABM의 adaptive한 특성은 항상 예측을 포함한다. 예측은 각 대안의 결과에 대한 기대이고 아주 간단한 에이전트의 결정도 예측을 포함한다. 심지어 극단적으로 간단한 예측을 사용해도 complex behavior가 나타날 수 있다. ABM의 핵심 부분을 만들기 위해 test와 explore로 submodel을 분리하는 것이 시간과 노력을 아낄 수 있고, 모든 가능한 조건하에서 행동을 실행해볼 수 있다는 장점이 있다. 
&lt;br /&gt;&lt;br /&gt;
앞서 살펴본 비즈니스 투자모델의 목적함수를 다음과 같이 바꾸어 실행해볼 수 있다. 여기서 control variable은 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;decision-time-horizon&lt;/b&gt;이다.
&lt;ol&gt;
&lt;li&gt;수익과 위험을 모두 고려하여 예상되는 투자자의 자산을 최대화하는 것&lt;br /&gt;
utility = turtles-wealth + (profit * &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;decision-time-horizon&lt;/b&gt;) &lt;br /&gt;
if utility $\le$ 0 then report 0, else &lt;br /&gt;
utility = utility * ((1-annual-risk) * &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;decision-time-horizon&lt;/b&gt;) &lt;/li&gt;
&lt;li&gt;위험은 무시하고 수익만을 최대화 하는 것 &lt;br /&gt;
utility = profit&lt;/li&gt;
&lt;li&gt;마이너스 수익과 위험을 피하는 것&lt;br /&gt;
utility = turtles-wealth + (profit * &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;decision-time-horizon&lt;/b&gt;) &lt;br /&gt;
if utility $\le$ 0 then report 0, else &lt;br /&gt;
utility = utility * ((1-annual-risk)^&lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;decision-time-horizon&lt;/b&gt;)&lt;/li&gt;
&lt;/ol&gt;
이 때 투자자의 자산은 다음과 같이 계산된다. wealth = 0 인 경우에는 실패로 카운트한다. 
&lt;ul&gt;
wealth = wealth + profit &lt;br /&gt;
if wealth $\le$ 0 then wealth = 0 &lt;br /&gt;
if random-float 1.0 &amp;lt; annual-risk then wealth = 0 
&lt;/ul&gt;
실험 결과 투자자들은 decision-time-horizon에 상관없이 시뮬레이션이 진행됨에 따라 위험도가 낮은 투자쪽으로 이동한다.  
&lt;br /&gt;&lt;br /&gt;
&lt;span style=&quot;font-weight:700; font-size:1.3em;  margin-right: 1em;&quot;&gt;
Submodel
&lt;/span&gt;
&lt;br /&gt;&lt;br /&gt;
Submodel로 분리하여 분석하는 것은 ABM의 각 부분을 시험하고 완전히 이해하도록 돕는 역할을 하기 때문에 중요하다. 투자 모델에서는 투자자의 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;utility&lt;/b&gt; 값이 투자 수익과 실패 위험에 따라 어떻게 변하는지 알고 싶어한다. 이 때 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;등고선도(contour plots)&lt;/b&gt;를 그려보면 파라미터를 동시에 고려하여 어떻게 submodel이 행동했는지 알 수 있다. 동일한 등고선에 속하는 이익과 위험의 조합은 동일한 효용을 제공한다.

&lt;br /&gt;&lt;br /&gt;
Current investor wealth = 0, Time horizon = 5인 경우 &lt;br /&gt;
효용(utility)은 이익(profit)에 따라 크게 다르지만 위험(risk)에 대해서는 거의 다르지 않다.&lt;br /&gt;&lt;br /&gt;

Current investor wealth = 100000, Time horizon = 5인 경우&lt;br /&gt;
효용(utility)은 이익(profit)과 위험(risk) 모두에 따라 영향을 받는다. 이 경우 실패하면 비용이 더 들기 때문에 투자자가 돈을 더 가지고 있을 때 위험이 좀 더 중요한 요소가 된다. 투자자들은 전체 자산을 잃는 위험을 줄이기 위해 negative income을 선택할 수도 있다. 투자자가 자산을 축적할 때 손실을 흡수하여 위험을 줄일 수 있는 이 선택은 시뮬레이션을 하는 동안 투자자가 왜 저소득(lower-income), 저위험(lower-risk) 투자로 이동하는지 설명한다.&lt;br /&gt;&lt;br /&gt;

Current investor wealth = 0, Time horizon = 25인 경우&lt;br /&gt;
등고선이 (1)의 경우 보다 더 곡선이다. 이익과 위험사이의 trade-off는 투자자가 낮은 위험에서 높은 위험으로 가거나 낮은 이익에서 높은 이익으로 전환함에 따라 더 많이 변화한다. 이익이 낮을 때는 효용이 이익에만 민감하지만, 이익의 값이 높아질수록 효용이 위험에 점점 더 의존하게 되고 등고선의 모양은 점점 더 수평이 된다. &lt;br /&gt;&lt;br /&gt;

Current investor wealth = 100000, Time horizon = 25인 경우&lt;br /&gt;
이익이 -4000이하인 경우 효용은 0이고 (2)와 대조적이다. time horizon이 길수록 투자자들은 위험 감소에 대한 대가로 단기 손실을 감수하지 않게 된다. 이는 직관에 어긋나는 결과이다. (counterintuitive)
이런 결과가 나타난 이유는 에이전트인 투자자가 선택하는 투자 이익과 위험은 매년 변화할 기회가 있음에도 불구하고 내내 지속될 것이라는 잘못된 예측을 사용하기 때문이다. &lt;br /&gt;&lt;br /&gt;

&lt;/div&gt;
</description>
        <pubDate>Thu, 09 Apr 2020 18:00:08 +0000</pubDate>
        <link>http://munjeongkang.github.io/ABM11/</link>
        <guid isPermaLink="true">http://munjeongkang.github.io/ABM11/</guid>
        
        
        <category>수업</category>
        
      </item>
    
      <item>
        <title>Agent Based Modeling - Adaptive Behavior and Objectives</title>
        <description>&lt;hr /&gt;

&lt;div style=&quot;font-weight:500; font-size:1.0em; margin-left: 1em; margin-right: 1em;text-align:justify; &quot;&gt;

&lt;span style=&quot;font-weight:700; font-size:1.3em;  margin-right: 1em;&quot;&gt;
Adaptive Behavior 
&lt;/span&gt;
&lt;br /&gt;&lt;br /&gt;

&lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;Adaptive Traits&lt;/b&gt;를 최적화하는 과정은 다음과 같다. 
&lt;ol&gt;
&lt;li&gt;대체할 수 있는것(alternatives)이 확인한다.&lt;/li&gt;
&lt;li&gt;유효하지 않은 것은 제거한다.&lt;/li&gt;
&lt;li&gt;각각의 alternatives가 목적 함수를 얼마나 충족하는지에 따라 유효한 것을 평가한다.&lt;/li&gt;
&lt;li&gt;가장 좋은 목적함수 값을 주는 최적의 alternative를 선택한다.&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li type=&quot;circle&quot;&gt;Agentset (대체할 수 있는 후보) : turtles, links, turtles-at, turtles-on, turtle-here, link-neighbors, in-link-neighbors, out-link-neighbors 등 &lt;/li&gt;
&lt;li type=&quot;circle&quot;&gt;Agentset의 부분집합 만들기 : other, in-radius, in-cone, with, with-max, max-n-of, with-min, and, or, patch-set, turtle-set, link-set 등&lt;/li&gt;
&lt;/ul&gt;
max-one-of, min-one-of, with-max, with-min 등을 사용하여 목적함수에 대해 가장 좋은 alternative를 확인한다. 비즈니스 투자 모델의 경우 매년 투자자는 유효한(feasible) 투자의 효용을 계산하고 가장 좋은 투자를 선택한다. 이 모델의 목적은 최대 효용을 가지는 항목에 투자를 함으로써 자산을 최대화 하는 것이다. 이 때, 투자자들은 유효한 투자의 수익에 대한 정보는 가지고 있다고 가정한다.
&lt;br /&gt;&lt;br /&gt;
 이 모델에 대한 새로운 파라미터로 profit-mulriplier(0.5~1.0)와 risk-multiplier(1.0~2.0)를 추가해서 분석해 보면 다음과 같은 결과를 얻을 수 있다. 어느 한 가지는 고정하고 값을 변화시켰을 때 위험과 이익이 변하는 양상을 볼 수 있다. 
&lt;br /&gt;&lt;br /&gt;
&lt;div style=&quot;border: 1px; float: right;margin-left: 1em; margin-right: 1em; &quot;&gt;
&lt;img src=&quot;/images/post_img/NL20.png&quot; width=&quot;290&quot; height=&quot;300&quot; /&gt;
&lt;/div&gt;
&lt;div style=&quot;border: 1px; margin-left: 1em; margin-right: 1em; &quot;&gt;
&lt;img src=&quot;/images/post_img/NL19.png&quot; width=&quot;290&quot; height=&quot;300&quot; /&gt;
&lt;/div&gt;

&lt;span style=&quot;font-weight:700; font-size:1.3em;  margin-right: 1em;&quot;&gt;
Satisficing decision
&lt;/span&gt;
&lt;br /&gt;&lt;br /&gt;

Alternative를 찾을 때 꼭 최적의 값을 찾지 않아도 되는 경우가 있다. 이 때는 적당히 좋은 값(good enough)을 찾는다. 비즈니스 투자 모델의 경우 투자자들은 그들이 소유한 종목 이외의 이익이나 실패 위험을 알 수 없다. 그렇기 때문에 적당한 한계점(threshold)을 기준으로 잡아 종목을 선택할지 말지 결정한다. 
&lt;br /&gt;&lt;br /&gt;
&lt;/div&gt;
</description>
        <pubDate>Thu, 09 Apr 2020 18:00:08 +0000</pubDate>
        <link>http://munjeongkang.github.io/ABM10/</link>
        <guid isPermaLink="true">http://munjeongkang.github.io/ABM10/</guid>
        
        
        <category>수업</category>
        
      </item>
    
      <item>
        <title>Agent Based Modeling - Sensing</title>
        <description>&lt;hr /&gt;

&lt;div style=&quot;font-weight:500; font-size:1.0em; margin-left: 1em; margin-right: 1em;text-align:justify; &quot;&gt;
&lt;span style=&quot;font-weight:700; font-size:1.3em;  margin-right: 1em;&quot;&gt;
Sensing
&lt;/span&gt;
&lt;br /&gt;&lt;br /&gt;
에이전트가 어떤 정보를 가지고 있는지, 어떻게 그것을 얻었는지에 대한 것이 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;Sensing&lt;/b&gt;이다. 에이전트는 주로 환경이나 다른 에이전트로 부터 정보를 얻고 그 정보에 의해 반응한다. 에이전트가 어떤 변수를 사용했는지, 무엇으로부터 정보를 얻었는지, 어떻게 정보를 얻었는지가 모델링 sensing의 핵심이다. 
&lt;br /&gt;&lt;br /&gt;
&lt;span style=&quot;font-weight:700; font-size:1.3em;  margin-right: 1em;&quot;&gt;
Scope of Variables
&lt;/span&gt;
&lt;br /&gt;&lt;br /&gt;
ABM에서 사용할 수 있는 변수들은 다음과 같다. 
&lt;ul&gt;
&lt;li type=&quot;circle&quot;&gt;Global Variables : 어떤 객체든지 항상 변할 수 있는 값이다. (Model-level, Environment parameters, Interface, Behavior space 등) &lt;/li&gt;
&lt;li type=&quot;circle&quot;&gt;Patch Variables : &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;patches-own&lt;/b&gt; 사용가능, pcolor, pxcor 등 patch에 관련된 것을 사용한다. turtle은 그들이 위치한 patch의 변수에 직접적으로 접근가능하다.&lt;/li&gt;
&lt;li type=&quot;circle&quot;&gt;Turtle and Link Variables : &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;turtles-own&lt;/b&gt;, &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;links-own&lt;/b&gt; 사용가능, 각각의 turtle 또는 link에만 한정된다.&lt;/li&gt;
&lt;li type=&quot;circle&quot;&gt;Local Variables : &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;let&lt;/b&gt; 명렁어를 사용하여 만들고 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;set&lt;/b&gt;을 사용하여 값을 변환시킨다. 객체가 생성되는 장소에서만 생성할 수 있으며, 다른 객체는 접근할 수 없다. procedure(또는 [])가 종료되면 사라진다. &lt;/li&gt;
&lt;/ul&gt;
다른 객체의 변수를 사용하는 예시로 다음의 코드를 사용할 수 있으며 이를 응용해 다음과 같이 서로의 색을 바꾸는 코드를 짤 수 있다.
&lt;br /&gt;
&lt;ul&gt;
&lt;code&gt;let max-neighbor-value max [value] of neighbors&lt;/code&gt; &lt;br /&gt;
&lt;code&gt;ask neighbors [set value 99]&lt;/code&gt; &lt;br /&gt;
&lt;code&gt;ask neighbors [set value ([value] of myself)]&lt;/code&gt;
&lt;/ul&gt;
&lt;div style=&quot;border: 1px; float: right;margin-left: 1em; margin-right: 1em; &quot;&gt;
&lt;img src=&quot;/images/post_img/NL18.png&quot; width=&quot;290&quot; height=&quot;300&quot; /&gt;
&lt;/div&gt;
&lt;div style=&quot;border: 1px; margin-left: 1em; margin-right: 1em; &quot;&gt;
&lt;img src=&quot;/images/post_img/switch.gif&quot; width=&quot;290&quot; height=&quot;300&quot; /&gt;
&lt;/div&gt;
&lt;br /&gt;
&lt;span style=&quot;font-weight:700; font-size:1.3em;  margin-right: 1em;&quot;&gt;
The Business Investor Model
&lt;/span&gt;
&lt;br /&gt;&lt;br /&gt;
 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;비즈니스 투자 모델&lt;/b&gt;은 수익과 위험정도가 다른 투자 후보들이 있을 때, 어떤 것에 투자할지에 대해 시뮬레이션하는 것이다. 모델의 목적은 주어진 정보를 사용하여 모델의 emergent output에 대한 sensing의 영향을 알아보는 것이다. 여기서 turtle이 투자자, patch가 투자 후보들이다. turtle의 변수로 location, current wealth(&lt;i&gt;W&lt;/i&gt;)가 있고, patch의 변수로 annual net profit(&lt;i&gt;P&lt;/i&gt;), annual risk-probability of losing all its wealth(&lt;i&gt;F&lt;/i&gt;)가 있다. 모델의 time step은 1년이고 25년까지 실행한다. time step마다 투자자는 어떤 곳에 투자할지 선택하고 자산이 업데이트된다. 
&lt;br /&gt;&lt;br /&gt;
이 모델에서는 수익은 높이고 위험은 줄이는 선택을 어떻게 할 것인지 정해야한다. time step마다 투자자의 평균 자산,평균 수익, 위험, 실패한 투자자의 수가 output으로 나오고 수익과 위험 사이의 trade-off를 통해 발현된다. 투자자인 turtle은 투자 후보들 중에서 목적함수의 값을 최대화하는 이웃의 patch로 이동한다. (현재 위치가 제일 좋은 선택이면 움직이지 않는다.) 여기서 목적함수는 마지막에 예측되는 효용 (미래의 자산)을 최대화 하는 것이다. 여기서 $T$는 time horizon을 뜻한다.
&lt;br /&gt;&lt;br /&gt;
&lt;p align=&quot;center&quot;&gt;
$U = (W+TP)(1-F)^T$
&lt;br /&gt;
&lt;/p&gt;
투자자들은 그들의 patch와 인접한 이웃 patch의 수익과 위험을 안다고 가정하고, 이미 다른 투자자가 차지한 patch로는 이동하지 않는다. &lt;i&gt;P&lt;/i&gt;, &lt;i&gt;F&lt;/i&gt;, &lt;i&gt;location&lt;/i&gt; 등 모델의 초기상태, 투자실패, 동률일 때 무작위로 움직이는 것 등은 확률적이며 에이전트의 위치, 평균 수익과 위험, 평균 투자자산, time step별 각 투자자의 상태를 관찰(observation)할 수 있다. 100명의 투자자가 랜덤으로 위치하고 &lt;i&gt;W&lt;/i&gt;의 초기값은 0이다. 
&lt;br /&gt;&lt;br /&gt;
&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/post_img/invest.gif&quot; width=&quot;600&quot; height=&quot;300&quot; /&gt;
&lt;br /&gt;
&lt;/p&gt;
여기서 만약 투자자들이 이웃만이 아닌 더 넓은 범위의 투자도 고려할 수 있다면 투자자의 자산을 더 증가시킬 수 있는지 의문이 든다. 실제로 Sensing range를 넓혀가면서 실험해보면 이웃만 살펴보는 것보다 더 넓은 범위를 고려하는게 더 좋다. 하지만 일정 범위를 지나서는 아무리 넓은 범위를 고려해도 투자 자산이 증가하지는 않는다. 
&lt;br /&gt;&lt;br /&gt;
 
&lt;/div&gt;
</description>
        <pubDate>Wed, 08 Apr 2020 18:00:08 +0000</pubDate>
        <link>http://munjeongkang.github.io/ABM9/</link>
        <guid isPermaLink="true">http://munjeongkang.github.io/ABM9/</guid>
        
        
        <category>수업</category>
        
      </item>
    
      <item>
        <title>Agent Based Modeling - Emergence</title>
        <description>&lt;hr /&gt;
&lt;p&gt;&lt;span style=&quot;font-weight:700; font-size:1.3em; margin-left: 0.8em; margin-right: 1em;&quot;&gt;
발현 (Emergence)
&lt;/span&gt;
&lt;br /&gt;&lt;/p&gt;
&lt;div style=&quot;font-weight:500; font-size:1.0em; margin-left: 1em; margin-right: 1em;text-align:justify; &quot;&gt;
&lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;Emergence&lt;/b&gt;는 ABM의 가장 중요하고 독특한 특징으로, 복잡하고 예상치 못한 시스템 다이나믹스가 기본적인 프로세스를 모델링하는 방법에서 나온다는 것이다. 여기서 예상치 못한다는 뜻은 단순히 생각만으로 예측하기 어렵거나 불가능함을 뜻한다. Emergence는 단순히 모델 객체의 성질이 합쳐진 것도, 각각의 성질로부터 쉽게 예측될 수 있는 것도 아니다. 
&lt;br /&gt;&lt;br /&gt;
&lt;div style=&quot;border: 1px; float: right;margin-left: 1em; margin-right: 1em; &quot;&gt;
&lt;img src=&quot;/images/post_img/emergence.gif&quot; width=&quot;290&quot; height=&quot;300&quot; /&gt;
&lt;/div&gt;
&lt;div style=&quot;border: 1px; margin-left: 2em; margin-right: 1em; &quot;&gt;
&lt;img src=&quot;/images/post_img/NL15.png&quot; width=&quot;290&quot; height=&quot;300&quot; /&gt;
&lt;/div&gt;
&lt;br /&gt;
관련된 간단한 문제를 만들어보자. 40개의 turtle을 만들고 &#39;speed&#39; attribute를 추가한다. turtle들을 앞으로 10만큼 이동시키고 오른쪽으로 90도 돌리면 어떤 모양이 될까? 놀랍게도 왼쪽 그림과 같이 원 모양이 만들어진다. 이를 turtle의 속도만큼 앞으로 이동하고 오른쪽으로 1만큼 계속 돌리면 오른쪽 그림과 같이 원이 커졌다가 줄어드는 현상을 볼 수 있다. 
&lt;br /&gt;&lt;br /&gt;
&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/post_img/birthrate.gif&quot; width=&quot;290&quot; height=&quot;250&quot; /&gt;
&lt;/p&gt;
&lt;br /&gt;
또 다른 예시로 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;Simple Birth Rates Model&lt;/b&gt;을 들 수 있다. 이 모델은 두 개의 종 (빨간색 turtle, 파란색 turtle) 사이의 출생률 차이가 각 모집단의 객체수에 어떤 영향을 미치는지 시뮬레이션하기 위해 설계되었다. 두 종은 time step 마다 생산하는 자손의 수에만 차이가 있고 죽을 확률은 같다. 두 종의 상대적인 출생률에 따라 한 종이 멸종할 때까지 얼마나 시간이 걸리는지 알아본다. 이 모델에서 fertility를 조절하여 출생률을 바꿀 수 있으며, 예를 들어 fertility 3.4라면 최소 3명의 자손을 낳고 40%의 확률로 4번째 자손을 낳을 수 있다는 뜻이다. 두 종의 출생률이 비슷하면 어느 한 종이 멸종하기까지 오랜 시간이 걸리고 출생율의 차이가 커질수록 출생율이 작은 종이 더 빨리 멸종하는 것을 확인할 수 있다. 
&lt;br /&gt;&lt;br /&gt;
&lt;span style=&quot;font-weight:700; font-size:1.3em;  margin-right: 1em;&quot;&gt;
민감도 분석 (Sensitivity Experiments)
&lt;/span&gt;
&lt;br /&gt;&lt;br /&gt;
민감도 분석은 시뮬레이션에서 특정한 파라미터나 input에 따라 모델이 어떻게 변하는지 분석하는 것이다. 이 때, 모델은 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;확률적인(stochastic)&lt;/b&gt; 특성을 가지기 때문에 같은 파라미터로 시뮬레이션해도 완전히 똑같은 결과가 나오지 않는다. 따라서 각각의 시나리오에 대해 최소 30번 이상 실행하여 평균값을 얻어야 한다. NetLogo에서는 Tools &amp;gt; BehaviorSpace 탭으로 들어가면 여러 조건을 주고 실험할 수 있으며 결과를 엑셀 등으로 저장할 수 있다. 
&lt;br /&gt;&lt;br /&gt;
&lt;div style=&quot;border: 1px; float: right;margin-left: 1em; margin-right: 1em; &quot;&gt;
&lt;img src=&quot;/images/post_img/NL17.png&quot; width=&quot;290&quot; height=&quot;300&quot; /&gt;
&lt;/div&gt;
&lt;div style=&quot;border: 1px; margin-left: 1em; margin-right: 1em; &quot;&gt;
&lt;img src=&quot;/images/post_img/NL16.png&quot; width=&quot;310&quot; height=&quot;310&quot; /&gt;
&lt;/div&gt;
&lt;br /&gt;
실험결과를 이용해 오른쪽 그림과 같이 boxplot을 그려 분석해볼 수 있다. 빨간색 turtle의 출생률은 2로 고정시키고 파란색 turtle의 출생률을 증가시켰을 때, 빨간색 turtle이 멸종하는 시간이 점점 더 짧아짐을 볼 수 있다.
&lt;br /&gt;&lt;br /&gt;
앞서 살펴본 Flocking 모델에서도 Emergnet behavior를 관찰할 수 있다. 그러나 완전히 발현되기까지 warm-up 단계(대략 400ticks 부터 발현)를 거칠 수도 있다. Emergence를 구체화하기 위해서는 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;정량적인 방법 (quantitative measurements)&lt;/b&gt;이 필요하며, 예를 들어 flockmates의 수나 거리를 평균적으로 구해보거나 방향에 대한 표준편차 등을 구해보는 것 등이 있다. 또는 대조적인 시나리오를 비교해보는 방법도 있다. Flocking 모델을 예로 들면, flockmate를 범위 안에 있는 모든 turtle로 정의할지, 가장 가까운 turtle만 정의할지에 따라 결과가 달라진다. 
&lt;br /&gt;&lt;br /&gt;


&lt;/div&gt;
</description>
        <pubDate>Wed, 08 Apr 2020 18:00:08 +0000</pubDate>
        <link>http://munjeongkang.github.io/ABM8/</link>
        <guid isPermaLink="true">http://munjeongkang.github.io/ABM8/</guid>
        
        
        <category>수업</category>
        
      </item>
    
      <item>
        <title>Agent Based Modeling - Testing Your Program</title>
        <description>&lt;hr /&gt;

&lt;p&gt;&lt;span style=&quot;font-weight:700; font-size:1.3em; margin-left: 0.8em; margin-right: 1em;&quot;&gt;
Overview of a Simulation Study
&lt;/span&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;div style=&quot;font-weight:500; font-size:1.0em; margin-left: 1em; margin-right: 1em;text-align:justify; &quot;&gt;
&lt;ol&gt;
&lt;li&gt;시스템 이해하기 (시스템에 관한 사전지식 등)&lt;/li&gt;
&lt;li&gt;목표를 분명히 하기&lt;/li&gt;
&lt;li&gt;모델에 대한 묘사 공식화하기&lt;/li&gt;
&lt;li&gt;모델링 소프트웨어로 변환하기&lt;/li&gt;
&lt;li&gt;&lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;프로그램 확인하기(verify, debugging)&lt;/b&gt;&lt;/li&gt;
&lt;li&gt;&lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;모델 확인하기(vaildate)&lt;/b&gt;&lt;/li&gt;
&lt;li&gt;실험 디자인하기&lt;/li&gt;
&lt;li&gt;모델 실행하기&lt;/li&gt;
&lt;li&gt;결과에 대해 insight를 얻고 분석하여 문서화하기&lt;/li&gt;
&lt;/ol&gt;

모델을 테스트하는 3단계는 &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;Vaildation&lt;/b&gt;, &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;Verification&lt;/b&gt;, &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;Debugging&lt;/b&gt;이다. Verification은 모델 formulation이 소프트웨어에서 정확하게 실행되는지 확인하는 것이다. 즉, 원하는대로 프로그램이 실행되는지 확실히 하는 것이다. 이 과정에서 실수를 찾고 고치는 노력이 요구되며 모델링의 효율을 높이기 위해 가능한 빨리 테스트를 시작하고 코드를 지속적으로 테스트해야한다. (디버깅도 verification의 한 부분이다.) Vaildation은 모델이 실제 상황을 충분히 잘 반영하고 있는지 확인하는 것이다. ABM에서는 특히 예측되지 않은 결과(Unexpected Result)에 대한 주의가 필요하다. 결과가 새롭고(novel) 중요한지, 모델 디자인은 의심스럽지 않은지, 프로그래밍 실수가 있는지 등을 확인해야한다.  
&lt;br /&gt; &lt;br /&gt;
&lt;span style=&quot;font-weight:700; font-size:1.3em; margin-right: 1em;&quot;&gt;
Common Kinds of Errors
&lt;/span&gt;
&lt;br /&gt;&lt;br /&gt;
흔히 발생하는 에러들은 다음과 같다. 
&lt;br /&gt;&lt;br /&gt;
&lt;li type=&quot;circle&quot;&gt;Typographical Errors (타이핑을 잘못한 경우)&lt;/li&gt;
&lt;li type=&quot;circle&quot;&gt;Syntax Errors (잘못된 구문)&lt;/li&gt;
&lt;li type=&quot;circle&quot;&gt;isunderstanding Primitives (원래 생각했던대로 정확하게 구현을 못한 경우)&lt;/li&gt; 
&lt;li type=&quot;circle&quot;&gt;Wrong Display Setting&lt;/li&gt;
&lt;li type=&quot;circle&quot;&gt;Run-Time Errors (프로그램을 실행할 때, 컴퓨터가 다룰 수 없는 무언가가 있는 경우)&lt;/li&gt;
&lt;li type=&quot;circle&quot;&gt; &lt;b style=&quot;color:#d7385e;font-size:1.2&quot;&gt;Logic Errors&lt;/b&gt; (잘못된 식, 부정확한 조건 등)&lt;/li&gt; 
&lt;li type=&quot;circle&quot;&gt;Formulation Errors (가정, 알고리즘, 파라미터 값에 대한 에러, validation issues)&lt;/li&gt;
&lt;br /&gt;
&lt;span style=&quot;font-weight:700; font-size:1.3em; margin-right: 1em;&quot;&gt;
Techniques for Debugging and Testing
&lt;/span&gt;
&lt;br /&gt;&lt;br /&gt;
실수를 줄이기 위해서는 Debugging과 Testing 과정이 중요하며 다음과 같은 기법들이 있다.
&lt;br /&gt;&lt;br /&gt;

&lt;li type=&quot;circle&quot;&gt; Syntax Checking (코드 작성시 수시로 syntax를 확인하는 습관을 가지는 것)&lt;/li&gt;
&lt;li type=&quot;circle&quot;&gt;Visual Testing (시각적으로 확인하는 것)&lt;/li&gt;
&lt;li type=&quot;circle&quot;&gt;Print Statement (어떻게 작동하는지 프린트해서 확인하는 것)&lt;/li&gt;
&lt;li type=&quot;circle&quot;&gt;Spot Tests with Agent Monitors (NetLogo View에 있는 Agent Monitor로 확인하는 것)&lt;/li&gt;
&lt;li type=&quot;circle&quot;&gt;Stress Tests (extreme 값을 파라미터나 input으로 넣어 프로그램을 실행하는 것, 평범한 조건에서 숨겨진 에러를 발견할 수도 있다.), 
&lt;li type=&quot;circle&quot;&gt;Test Procedure (중간 output을 만들어 테스트 해보는 것)&lt;/li&gt; 
&lt;li type=&quot;circle&quot;&gt;Test Programs (특정한 프로그램 아이디어를 테스트하기 위해 짧은 프로그램으로 분리하여 실행하는 것)&lt;/li&gt; 
&lt;li type=&quot;circle&quot;&gt;Code Reviews (동료들과 리뷰해보는 것, 다른 사람이 확인하면 실수가 발견될 수 있고 코드를 잘 정리하고 이해하기 쉽게 하기위해서)&lt;/li&gt; 
&lt;li type=&quot;circle&quot;&gt;Statistical Analysis of File OutPut (예상했던대로 모델이 formulation 되었는지 확인하기 위해 모델의 핵심 부분을 file output으로 적어 분석해보는 것)&lt;/li&gt; 
&lt;li type=&quot;circle&quot;&gt;Independent Reimplementation of Submodels (엑셀이나 R, Python 등 다른 플랫폼으로 확인해보는 것)&lt;/li&gt;
&lt;li type=&quot;circle&quot;&gt;Documentation of Tests(사용된 test의 종류, 모델을 실행한 방법과 결과 등을 문서화하는 것)&lt;/li&gt;

&lt;br /&gt;

&lt;/li&gt;&lt;/div&gt;
</description>
        <pubDate>Tue, 07 Apr 2020 18:00:08 +0000</pubDate>
        <link>http://munjeongkang.github.io/ABM7/</link>
        <guid isPermaLink="true">http://munjeongkang.github.io/ABM7/</guid>
        
        
        <category>수업</category>
        
      </item>
    
  </channel>
</rss>
